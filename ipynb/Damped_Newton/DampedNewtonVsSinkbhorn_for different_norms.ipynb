{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we benchmark the performance of Sinkhon vs damped Newton for different distance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1234)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path_to_new_folder = \"../Images\"\n",
    "os.makedirs(relative_path_to_new_folder, exist_ok = True)\n",
    "if not os.path.isdir('../Images/DampedNewtonVsSinkbhorn_for diff_norm_images'):\n",
    "    os.makedirs('../Images/DampedNewtonVsSinkbhorn_for diff_norm_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Different norms\"\"\"\n",
    "def p_norms( x, y, p ):\n",
    "   # L-1 norm\n",
    "   if p == 1:\n",
    "      return  abs( np.sum( x, 0 )[:,None] - np.sum( y, 0 )[None,:] )  \n",
    "   # L-2 norm\n",
    "   elif p == 2:\n",
    "      return  np.sum( x**2, 0 )[:,None] + np.sum( y**2, 0 )[None,:] - 2 * x.transpose().dot( y )\n",
    "   # L-4 norm\n",
    "   elif p == 4:\n",
    "    return np.sum( x**4, 0 )[:,None] + np.sum( y**4, 0 )[None,:] + 4 * ( x**3 ).transpose().dot( y ) - 4 * x.transpose().dot( y**3 ) + 6 * ( x**2 ).transpose().dot( y**2 )\n",
    "   # L-infty norm\n",
    "   elif p == 'inf':\n",
    "      return np.maximum( abs( x[0,:][:,None] - y[0,:][None,:] ), abs( x[1,:][:,None] - y[1:][None:] ) )\n",
    "\n",
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat( x, y ):\n",
    "    return np.sum( x**2, 0 )[:,None] + np.sum( y**2, 0 )[None,:] - 2 * x.transpose().dot( y )\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum( a )\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP( u, K, v ):\n",
    "    return u[:,None] * K * v[None,:]\n",
    "\n",
    "def plotp( x, col, plt, scale = 200, edgecolors = \"k\" ):\n",
    "  return plt.scatter( x[0,:], x[1,:], s = scale, edgecolors = edgecolors,  c = col, cmap = 'plasma', linewidths = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import computational_OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition( mat ):\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort( eig ) \n",
    "    eig = eig[ sorting_indices ]\n",
    "    v   = v[ : , sorting_indices ]    \n",
    "    print( \"List of smallest eigenvalues: \", eig[ : 10 ] )\n",
    "    print( \"List of largest  eigenvalues: \", eig[ - 10 : ] )\n",
    "    return eig, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preconditioners( num_eigs, modified_Hessian, N, ansatz = True ):\n",
    "    # Diagonalize\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh( modified_Hessian )\n",
    "    sorting_indices = np.argsort( eigenvalues )\n",
    "    eigenvalues  =  eigenvalues[ sorting_indices ]\n",
    "    eigenvectors = eigenvectors[ :,  sorting_indices ]\n",
    "    # Form null vector\n",
    "    if not ansatz:\n",
    "        null_vector = eigenvectors[ : , 0 ]\n",
    "    else:\n",
    "        null_vector = np.hstack( ( np.ones(N[0]), - np.ones(N[1]) ) )\n",
    "        norm = np.sqrt( N[0] + N[1] )\n",
    "        null_vector = null_vector/norm\n",
    "    # Form other vectors (only 13)\n",
    "    _,m = eigenvectors.shape\n",
    "    indices=[]\n",
    "    for i in range(num_eigs//2):\n",
    "        indices.append( m - i - 2 )\n",
    "        indices.append( i + 1 )\n",
    "    # end for\n",
    "    if num_eigs%2 !=0:\n",
    "        indices.append( m - 1 - ( num_eigs//2 ) )\n",
    "   \n",
    "    precond_vectors = eigenvectors[:, indices ]\n",
    "    precond_vectors = []\n",
    "    for index in indices:\n",
    "        precond_vectors.append( eigenvectors[:,index] )\n",
    "    # end for\n",
    "    return null_vector, precond_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [ 1000, 1200 ]\n",
    "epsilons = [ 0.1, 0.09, 0.05, 0.03 ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand( 2,N[0] ) - 0.5\n",
    "theta = 2 * np.pi * np.random.rand( 1, N[1] )\n",
    "r = 0.8 + .2 * np.random.rand( 1, N[1] )\n",
    "y = np.vstack( ( r * np.cos( theta ), r * np.sin( theta ) ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. L-1 norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print( \"Sinkhorn... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "SinkhornP_L_1 = []\n",
    "results_Sinkhorn_L_1 = []\n",
    "times_Sinkhorn_L_1 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 2 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "  #Kernel\n",
    "  K = np.exp( - C/eps )\n",
    "  print(\"For epsilon = \"+str(eps)+\":\")       \n",
    "  print( \" |- Iterating\" )\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                          a,\n",
    "                                          b,\n",
    "                                          u,\n",
    "                                          v,\n",
    "                                          eps )\n",
    "  out = Optimizer._update( max_iterations = 10000 )\n",
    "  results_Sinkhorn_L_1.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn_L_1.append( end - start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  u_opt = np.exp( out['potential_f']/eps )\n",
    "  K = np.exp( - C/eps )\n",
    "  v_opt =  np.exp( out['potential_g']/eps )\n",
    "  P_opt = GetP( u_opt, K, v_opt )\n",
    "  SinkhornP_L_1.append( P_opt )\n",
    "# end for "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn_L_1) ):\n",
    "  error = np.asarray( results_Sinkhorn_L_1[i]['error_a'] ) + np.asarray( results_Sinkhorn_L_1[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend( loc = 'upper right' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ConvergenceSinkhornvaryingepsilonL1.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Damped Newton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton\n",
    "print( \"Damped Newton... \" )\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "dampedNewtonP_L_1 = []\n",
    "results_dampedNewton_L_1  = []\n",
    "times_dampedNewton_L_1    = []\n",
    "Hessians_dampedNewton_L_1 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 1 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( -C/eps )\n",
    "    f, g = a, b\n",
    "    print( \" |- Iterating\")  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton( K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                f,\n",
    "                                                g,\n",
    "                                                eps,\n",
    "                                                rho,\n",
    "                                                c )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                debug = False )\n",
    "    end = time.time()\n",
    "    if out != -1:\n",
    "        results_dampedNewton_L_1.append( out )\n",
    "        times_dampedNewton_L_1.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonP_L_1.append( P_opt )\n",
    "        print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "        mat  = - eps * Optimizer.Hessian\n",
    "        diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "        mat = diag[:,None] * mat * diag[None,:]\n",
    "        Hessians_dampedNewton_L_1.append( mat )\n",
    "    else:\n",
    "        epsilons.remove( eps )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_dampedNewton_L_1[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/eigenhistunstabilizedL1.pdf\", format = 'pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_dampedNewton_L_1[-1], N, ansatz = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print( \"Damped Newton with preconditioning and iterative inversion... \" )\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians_L_1 = []\n",
    "dampedNewtonwithprecondP_L_1 = []\n",
    "results_dampedNewtonwithprecond_L_1  = []\n",
    "times_dampedNewtonwithprecond_L_1    = []\n",
    "# Cost matrix\n",
    "C = p_norms( x, y, 1 )\n",
    "# a and b\n",
    "a = normalize( np.ones(N[0]) )\n",
    "b = normalize( np.ones(N[1]) )\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    if (f is None) or (g is None): \n",
    "        f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                        a,\n",
    "                                                                        b,\n",
    "                                                                        f,\n",
    "                                                                        g,\n",
    "                                                                        eps,\n",
    "                                                                        rho,\n",
    "                                                                        c,\n",
    "                                                                        null_vector,\n",
    "                                                                        precond_vectors[:] )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                iterative_inversion = 30,\n",
    "                                version = None,\n",
    "                                debug = False,\n",
    "                                optType= 'cg' )\n",
    "    results_dampedNewtonwithprecond_L_1.append( out )\n",
    "    end = time.time()\n",
    "    times_dampedNewtonwithprecond_L_1.append( end - start )\n",
    "    print( \" |- Computing P\" )\n",
    "    print( \"\" )\n",
    "    u_opt = np.exp( out['potential_f']/eps )\n",
    "    K = np.exp( - C/eps )\n",
    "    v_opt =  np.exp( out['potential_g']/eps )\n",
    "    P_opt = GetP( u_opt, K, v_opt )\n",
    "    dampedNewtonwithprecondP_L_1.append( P_opt )\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    final_modified_Hessians_L_1.append( Optimizer.modified_Hessian )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len(results_dampedNewtonwithprecond_L_1) ):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond_L_1[i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond_L_1[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ErrorLinesearchNewton_final_cgL1.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. L-2 norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print( \"Sinkhorn... \" )\n",
    "print(\"Doing for (\",N[0], N[1],\").\")\n",
    "SinkhornP_L_2 = []\n",
    "results_Sinkhorn_L_2 = []\n",
    "times_Sinkhorn_L_2 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 2 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "  #Kernel\n",
    "  K = np.exp( - C/eps )\n",
    "  print(\"For epsilon = \"+str(eps)+\":\")       \n",
    "  print( \" |- Iterating\" )\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                          a,\n",
    "                                          b,\n",
    "                                          u,\n",
    "                                          v,\n",
    "                                          eps )\n",
    "  out = Optimizer._update( max_iterations = 10000 )\n",
    "  results_Sinkhorn_L_2.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn_L_2.append( end - start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  u_opt = np.exp( out['potential_f']/eps )\n",
    "  K = np.exp( - C/eps )\n",
    "  v_opt =  np.exp( out['potential_g']/eps )\n",
    "  P_opt = GetP( u_opt, K, v_opt )\n",
    "  SinkhornP_L_2.append( P_opt )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn_L_2) ):\n",
    "  error = np.asarray( results_Sinkhorn_L_2[i]['error_a'] ) + np.asarray( results_Sinkhorn_L_2[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ConvergenceSinkhornvaryingepsilonL2.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "dampedNewtonP_L_2 = []\n",
    "results_dampedNewton_L_2  = []\n",
    "times_dampedNewton_L_2    = []\n",
    "Hessians_dampedNewton_L_2 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 2 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton( K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                f,\n",
    "                                                g,\n",
    "                                                eps,\n",
    "                                                rho,\n",
    "                                                c )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                debug = False )\n",
    "    end = time.time()\n",
    "    if out != -1:\n",
    "        results_dampedNewton_L_2.append( out )\n",
    "        times_dampedNewton_L_2.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonP_L_2.append( P_opt )\n",
    "        print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "        mat  = - eps * Optimizer.Hessian\n",
    "        diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "        mat = diag[:,None] * mat * diag[None,:]\n",
    "        Hessians_dampedNewton_L_2.append( mat )\n",
    "    else:\n",
    "        epsilons.remove( eps )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_dampedNewton_L_2[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/eigenhistunstabilizedL2.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_dampedNewton_L_2[-1], N, ansatz = False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton with preconditioning and iterative inversion... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians_L_2 = []\n",
    "dampedNewtonwithprecondP_L_2 = []\n",
    "results_dampedNewtonwithprecond_L_2  = []\n",
    "times_dampedNewtonwithprecond_L_2    = []\n",
    "# Cost matrix\n",
    "C = p_norms( x, y, 2 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    if (f is None) or (g is None): \n",
    "        f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                        a,\n",
    "                                                                        b,\n",
    "                                                                        f,\n",
    "                                                                        g,\n",
    "                                                                        eps,\n",
    "                                                                        rho,\n",
    "                                                                        c,\n",
    "                                                                        null_vector,\n",
    "                                                                        precond_vectors[:] )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                iterative_inversion = 30,\n",
    "                                version = None,\n",
    "                                debug = False,\n",
    "                                optType = 'cg' )\n",
    "    results_dampedNewtonwithprecond_L_2.append( out )\n",
    "    end = time.time()\n",
    "    times_dampedNewtonwithprecond_L_2.append( end - start )\n",
    "    print( \" |- Computing P\" )\n",
    "    print( \"\" )\n",
    "    u_opt = np.exp( out['potential_f']/eps )\n",
    "    K = np.exp( - C/eps )\n",
    "    v_opt =  np.exp( out['potential_g']/eps )\n",
    "    P_opt = GetP( u_opt, K, v_opt )\n",
    "    dampedNewtonwithprecondP_L_2.append( P_opt )\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    final_modified_Hessians_L_2.append( Optimizer.modified_Hessian )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len(results_dampedNewtonwithprecond_L_2) ):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond_L_2[i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond_L_2[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ErrorLinesearchNewton_final_cgL2.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. L4-norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn... \")\n",
    "print(\"Doing for (\",N[0], N[1],\").\")\n",
    "SinkhornP_L_4 = []\n",
    "results_Sinkhorn_L_4 = []\n",
    "times_Sinkhorn_L_4 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 4 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "  #Kernel\n",
    "  K = np.exp( - C/eps )\n",
    "  print(\"For epsilon = \"+str(eps)+\":\")       \n",
    "  print( \" |- Iterating\" )\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                          a,\n",
    "                                          b,\n",
    "                                          u,\n",
    "                                          v,\n",
    "                                          eps )\n",
    "  out = Optimizer._update( max_iterations = 10000 )\n",
    "  results_Sinkhorn_L_4.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn_L_4.append( end - start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  u_opt = np.exp( out['potential_f']/eps )\n",
    "  K = np.exp( - C/eps )\n",
    "  v_opt =  np.exp( out['potential_g']/eps )\n",
    "  P_opt = GetP( u_opt, K, v_opt )\n",
    "  SinkhornP_L_4.append( P_opt )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn_L_4) ):\n",
    "  error = np.asarray( results_Sinkhorn_L_4[i]['error_a'] ) + np.asarray( results_Sinkhorn_L_4[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ConvergenceSinkhornvaryingepsilonL4.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "dampedNewtonP_L_4 = []\n",
    "results_dampedNewton_L_4  = []\n",
    "times_dampedNewton_L_4    = []\n",
    "Hessians_dampedNewton_L_4 = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 4 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton( K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                f,\n",
    "                                                g,\n",
    "                                                eps,\n",
    "                                                rho,\n",
    "                                                c )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                debug = False )\n",
    "    end = time.time()\n",
    "    if out != -1:\n",
    "        results_dampedNewton_L_4.append( out )\n",
    "        times_dampedNewton_L_4.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonP_L_4.append( P_opt )\n",
    "        print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "        mat  = - eps * Optimizer.Hessian\n",
    "        diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "        mat = diag[:,None] * mat * diag[None,:]\n",
    "        Hessians_dampedNewton_L_4.append( mat )\n",
    "    else:\n",
    "        epsilons.remove( eps )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_dampedNewton_L_4[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    if not np.isnan(eigs[i]).any():\n",
    "        ax[i].hist( eigs[i], 50 )\n",
    "        ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "        ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "        ax[i].set_yscale( \"log\" )    \n",
    "    else:\n",
    "        print(\"The eigenvalues for \"+str(epsilons[i])+ \" contains Nans.\")\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/eigenhistunstabilizedL4.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_dampedNewton_L_4[-1], N, ansatz = False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton with preconditioning and iterative inversion... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians_L_4 = []\n",
    "dampedNewtonwithprecondP_L_4 = []\n",
    "results_dampedNewtonwithprecond_L_4 = []\n",
    "times_dampedNewtonwithprecond_L_4    = []\n",
    "# Cost matrix\n",
    "C = p_norms( x, y, 4 )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps ) \n",
    "    if (f is None) or (g is None): \n",
    "        f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                        a,\n",
    "                                                                        b,\n",
    "                                                                        f,\n",
    "                                                                        g,\n",
    "                                                                        eps,\n",
    "                                                                        rho,\n",
    "                                                                        c,\n",
    "                                                                        null_vector,\n",
    "                                                                        precond_vectors[:] )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                iterative_inversion = 30,\n",
    "                                version = None,\n",
    "                                debug = False,\n",
    "                                optType = 'cg' )\n",
    "    results_dampedNewtonwithprecond_L_4.append( out )\n",
    "    end = time.time()\n",
    "    times_dampedNewtonwithprecond_L_4.append( end - start )\n",
    "    print( \" |- Computing P\" )\n",
    "    print( \"\" )\n",
    "    u_opt = np.exp( out['potential_f']/eps )\n",
    "    K = np.exp( - C/eps )\n",
    "    v_opt =  np.exp( out['potential_g']/eps )\n",
    "    P_opt = GetP( u_opt, K, v_opt )\n",
    "    dampedNewtonwithprecondP_L_4.append( P_opt )\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    final_modified_Hessians_L_4.append( Optimizer.modified_Hessian )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len(results_dampedNewtonwithprecond_L_4) ):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond_L_4[i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond_L_4[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ErrorLinesearchNewton_final_cgL4.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. L-infinity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn... \")\n",
    "print(\"Doing for (\",N[0], N[1],\").\")\n",
    "SinkhornP_L_infty = []\n",
    "results_Sinkhorn_L_infty = []\n",
    "times_Sinkhorn_L_infty = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 'inf' )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "  #Kernel\n",
    "  K = np.exp( - C/eps )\n",
    "  print(\"For epsilon = \"+str(eps)+\":\")       \n",
    "  print( \" |- Iterating\" )\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                          a,\n",
    "                                          b,\n",
    "                                          u,\n",
    "                                          v,\n",
    "                                          eps )\n",
    "  out = Optimizer._update( max_iterations = 10000 )\n",
    "  results_Sinkhorn_L_infty.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn_L_infty.append( end - start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  u_opt = np.exp( out['potential_f']/eps )\n",
    "  K = np.exp( - C/eps )\n",
    "  v_opt =  np.exp( out['potential_g']/eps )\n",
    "  P_opt = GetP( u_opt, K, v_opt )\n",
    "  SinkhornP_L_infty.append( P_opt )\n",
    "  SinkhornP_L_infty.append( GetP( np.exp( out['potential_f']/eps ), K, np.exp( out['potential_g']/eps ) ) )  \n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 )  )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn_L_infty) ):\n",
    "  error = np.asarray( results_Sinkhorn_L_infty[i]['error_a'] ) + np.asarray( results_Sinkhorn_L_infty[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ConvergenceSinkhornvaryingepsilonLinfty.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton\n",
    "print(\"Damped Newton... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "dampedNewtonP_L_infty = []\n",
    "results_dampedNewton_L_infty  = []\n",
    "times_dampedNewton_L_infty    = []\n",
    "Hessians_dampedNewton_L_infty = []\n",
    "#Cost matrix\n",
    "C = p_norms( x, y, 'inf' )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton(  K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                f,\n",
    "                                                g,\n",
    "                                                eps,\n",
    "                                                rho,\n",
    "                                                c )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                debug = False )\n",
    "    end = time.time()\n",
    "    if out != -1:\n",
    "        results_dampedNewton_L_infty.append( out )\n",
    "        times_dampedNewton_L_infty.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonP_L_infty.append( P_opt )\n",
    "        print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "        mat  = - eps * Optimizer.Hessian\n",
    "        diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "        mat = diag[:,None] * mat * diag[None,:]\n",
    "        Hessians_dampedNewton_L_infty.append( mat )\n",
    "    else:\n",
    "        epsilons.remove( eps )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_dampedNewton_L_infty[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/eigenhistunstabilizedLinfty.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_dampedNewton_L_infty[-1], N, ansatz = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton with preconditioning and iterative inversion... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians_L_infty = []\n",
    "dampedNewtonwithprecondP_L_infty = []\n",
    "results_dampedNewtonwithprecond_L_infty  = []\n",
    "times_dampedNewtonwithprecond_L_infty    = []\n",
    "# Cost matrix\n",
    "C = p_norms( x, y, 'inf' )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    if (f is None) or (g is None): \n",
    "        f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                        a,\n",
    "                                                                        b,\n",
    "                                                                        f,\n",
    "                                                                        g,\n",
    "                                                                        eps,\n",
    "                                                                        rho,\n",
    "                                                                        c,\n",
    "                                                                        null_vector,\n",
    "                                                                        precond_vectors[:] )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                iterative_inversion = 30,\n",
    "                                version = None,\n",
    "                                debug = False,\n",
    "                                optType = 'cg' )\n",
    "    results_dampedNewtonwithprecond_L_infty.append( out )\n",
    "    end = time.time()\n",
    "    times_dampedNewtonwithprecond_L_infty.append( end - start )\n",
    "    print( \" |- Computing P\" )\n",
    "    print( \"\" )\n",
    "    u_opt = np.exp( out['potential_f']/eps )\n",
    "    K = np.exp( - C/eps )\n",
    "    v_opt =  np.exp( out['potential_g']/eps )\n",
    "    P_opt = GetP( u_opt, K, v_opt )\n",
    "    dampedNewtonwithprecondP_L_infty.append( P_opt )\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    final_modified_Hessians_L_infty.append( Optimizer.modified_Hessian )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len(results_dampedNewtonwithprecond_L_infty) ):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond_L_infty[i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond_L_infty[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ErrorLinesearchNewton_final_cgLinfty.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. 1-cosine similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn... \")\n",
    "print(\"Doing for (\",N[0], N[1],\").\")\n",
    "SinkhornP_cosine = []\n",
    "results_Sinkhorn_cosine = []\n",
    "times_Sinkhorn_cosine = []\n",
    "#Cost matrix\n",
    "C = 1 - ( x.transpose().dot( y ) )/( np.linalg.norm( x, 2 ) * np.linalg.norm( y, 2 ) )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "  #Kernel\n",
    "  K = np.exp( - C/eps )\n",
    "  print(\"For epsilon = \"+str(eps)+\":\")       \n",
    "  print( \" |- Iterating\" )\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                          a,\n",
    "                                          b,\n",
    "                                          u,\n",
    "                                          v,\n",
    "                                          eps )\n",
    "  out = Optimizer._update( max_iterations = 10000 )\n",
    "  results_Sinkhorn_cosine.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn_cosine.append( end - start  )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  u_opt = np.exp( out['potential_f']/eps )\n",
    "  K = np.exp( - C/eps )\n",
    "  v_opt =  np.exp( out['potential_g']/eps )\n",
    "  P_opt = GetP( u_opt, K, v_opt )\n",
    "  SinkhornP_cosine.append( P_opt )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn_cosine) ):\n",
    "  error = np.asarray( results_Sinkhorn_cosine[i]['error_a'] ) + np.asarray( results_Sinkhorn_cosine[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ConvergenceSinkhornvaryingepsilonLcosine.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton \n",
    "print(\"Damped Newton... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "dampedNewtonP_cosine = []\n",
    "results_dampedNewton_cosine  = []\n",
    "times_dampedNewton_cosine    = []\n",
    "Hessians_dampedNewton_cosine = []\n",
    "#Cost matrix\n",
    "C = 1 - ( x.transpose().dot( y ) )/( np.linalg.norm( x, 2 ) * np.linalg.norm( y, 2 ) )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton( K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                f,\n",
    "                                                g,\n",
    "                                                eps,\n",
    "                                                rho,\n",
    "                                                c )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                debug = False )\n",
    "    end = time.time()\n",
    "    if out != -1:\n",
    "        results_dampedNewton_cosine.append( out )\n",
    "        times_dampedNewton_cosine.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonP_cosine.append( P_opt )\n",
    "        print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "        mat  = - eps * Optimizer.Hessian\n",
    "        diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "        mat = diag[:,None] * mat * diag[None,:]\n",
    "        Hessians_dampedNewton_cosine.append( mat )\n",
    "    else:\n",
    "        epsilons.remove( eps )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_dampedNewton_cosine[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/eigenhistunstabilizedLcosine.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_dampedNewton_cosine[-1], N, ansatz = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damped Newton with preconditioning\n",
    "print(\"Damped Newton with preconditioning and iterative inversion... \")\n",
    "print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians_cosine = []\n",
    "dampedNewtonwithprecondP_cosine = []\n",
    "results_dampedNewtonwithprecond_cosine  = []\n",
    "times_dampedNewtonwithprecond_cosine    = []\n",
    "# Cost matrix\n",
    "C = 1 - ( x.transpose().dot( y ) )/( np.linalg.norm( x, 2 ) * np.linalg.norm( y, 2 ) )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "    #Kernel\n",
    "    K = np.exp( - C/eps )\n",
    "    if (f is None) or (g is None): \n",
    "        f, g = a, b\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                        a,\n",
    "                                                                        b,\n",
    "                                                                        f,\n",
    "                                                                        g,\n",
    "                                                                        eps,\n",
    "                                                                        rho,\n",
    "                                                                        c,\n",
    "                                                                        null_vector,\n",
    "                                                                        precond_vectors[:] )\n",
    "    out = Optimizer._update(    max_iterations = 50,\n",
    "                                iterative_inversion = 30,\n",
    "                                version = None,\n",
    "                                debug = False,\n",
    "                                optType = 'cg' )\n",
    "    results_dampedNewtonwithprecond_cosine.append( out )\n",
    "    end = time.time()\n",
    "    times_dampedNewtonwithprecond_cosine.append( end - start )\n",
    "    print( \" |- Computing P\" )\n",
    "    print( \"\" )\n",
    "    u_opt = np.exp( out['potential_f']/eps )\n",
    "    K = np.exp( - C/eps )\n",
    "    v_opt =  np.exp( out['potential_g']/eps )\n",
    "    P_opt = GetP( u_opt, K, v_opt )\n",
    "    dampedNewtonwithprecondP_cosine.append( P_opt ) \n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    final_modified_Hessians_cosine.append( Optimizer.modified_Hessian )\n",
    "# end for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len(results_dampedNewtonwithprecond_cosine) ):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond_cosine[i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond_cosine[i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkbhorn_for diff_norm_images/ErrorLinesearchNewton_final_cgLcosine.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
