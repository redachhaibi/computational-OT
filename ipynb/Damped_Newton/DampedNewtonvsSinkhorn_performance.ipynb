{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we compare the performance of the Sinkhorn and the damped Newton algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1234)\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path_to_new_folder = \"../Images\"\n",
    "os.makedirs(relative_path_to_new_folder, exist_ok = True)\n",
    "if not os.path.isdir('../Images/SinkhornvsDampedNewton_images'):\n",
    "    os.makedirs('../Images/SinkhornvsDampedNewton_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat( x, y ):\n",
    "    return np.sum( x**2, 0 )[:,None] + np.sum( y**2, 0 )[None,:] - 2 * x.transpose().dot( y )\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum( a )\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP( u, K, v ):\n",
    "    return u[:,None] * K *v[None,:]\n",
    "\n",
    "def plotp( x, col, plt, scale = 200, edgecolors = \"k\"):\n",
    "  return plt.scatter( x[0,:], x[1,:], s = scale, edgecolors = edgecolors,  c = col, cmap = 'plasma', linewidths = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import computational_OT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy regularized formulation\n",
    "\n",
    "The primal entropy regularized formulation of OT is given by:\n",
    "$$\n",
    "OT_{\\varepsilon}(\\alpha,\\beta) = min_{\\pi \\in \\mathcal{U}(\\alpha,\\beta)} \\langle C,\\pi \\rangle +\\varepsilon KL(\\pi\\|\\alpha \\otimes \\beta)\\ ,\n",
    "$$\n",
    "where\n",
    "$\\ \n",
    "KL(\\pi\\|\\alpha \\otimes \\beta) \n",
    "\\ $ is the KL-divergence and $\\ \\mathcal{U}(\\alpha,\\beta)=\\{\\pi: \\pi\\mathcal{1}=\\alpha, \\pi^{T}\\mathcal{1}=\\beta\\}$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sinkhorn iteration function\n",
    "The optimal coupling $\\pi^{*}$ has the following form :\n",
    "$$\n",
    "\\pi^{*} = \\alpha \\odot diag(u)K diag(v)\\odot \\beta\n",
    "$$\n",
    "and we know that $\\pi^{*}\\mathbb{1}=\\alpha$ and $(\\pi^{*})^{T}\\mathbb{1}=\\beta$.\n",
    "###\n",
    "Therefore, Sinkhorn updates is given by the following alternative projections\n",
    "$$\n",
    "u^{t+1}  \\leftarrow \\frac{1}{K(v^{t}\\odot \\beta)}\\ , \\\n",
    "v^{t+1}  \\leftarrow \\frac{1}{K^{T}(u^{t+1}\\odot \\alpha)}\\ , \n",
    "$$\n",
    "where \n",
    "$K = e^{-\\frac{C}{\\varepsilon}}\\in M_{n\\times m}(\\mathbb{R}),\\ \\alpha \\in \\mathbb{R}^{n},\\ \\beta \\in \\mathbb{R}^{m}\\ ,\\ u\\in \\mathbb{R}^{n},\\ v\\in \\mathbb{R}^{m}\\ and \\ (u^{0},v^{0})=(u,v)\\ .$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn( epsilons, N, x, y, iterations = 1000 ):\n",
    "    print(\"Sinkhorn... \")\n",
    "    print(\"Doing for (\",N[0], N[1],\").\")\n",
    "    SinkhornP                  = []\n",
    "    results_Sinkhorn           = []\n",
    "    times_Sinkhorn             = []\n",
    "    #Cost matrix\n",
    "    C = distmat( x, y )\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    for eps in epsilons:\n",
    "        print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "        #Kernel\n",
    "        K = np.exp( - C/eps )\n",
    "        print( \" |- Iterating\")\n",
    "        #Inflating\n",
    "        u = a\n",
    "        v = b\n",
    "        start = time.time()\n",
    "        Optimizer = computational_OT.sinkhorn(  K,\n",
    "                                                a,\n",
    "                                                b,\n",
    "                                                u,\n",
    "                                                v,\n",
    "                                                eps )\n",
    "        out = Optimizer._update( max_iterations = iterations )\n",
    "        results_Sinkhorn.append( out )\n",
    "        end = time.time()\n",
    "        times_Sinkhorn.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        SinkhornP.append( P_opt )\n",
    "    # end for\n",
    "    return {\n",
    "        'results_list': results_Sinkhorn,\n",
    "        'time_stamps' : times_Sinkhorn,\n",
    "        'Ps'          : SinkhornP\n",
    "    }\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damped Newton(without preconditionING) iteration function\n",
    "\n",
    "The dual formulation of OT is given by\n",
    "$$\n",
    "OT_{\\varepsilon} = \\max_{f\\in \\mathbb{R}^{n}, g\\in\\mathbb{R}^{m}} \\langle f, \\alpha \\rangle + \\langle g, \\beta \\rangle - \\varepsilon\\left(\\langle\\alpha \\otimes \\beta, e^{\\frac{f}{\\varepsilon}}\\odot K \\odot e^{\\frac{g}{\\varepsilon}}  \\rangle-1\\right)\\ ,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha \\in \\mathcal{M}_{1}(\\mathcal{X}),\\ \\beta \\in \\mathcal{M}_{1}(\\mathcal{Y}),\\ \\varepsilon>0,\\ f\\in\\mathbb{R}^{n},\\ g\\in \\mathbb{R}^{m}\\ .\n",
    "$$\n",
    "\n",
    "The Hessian is given by \n",
    "$\\nabla^{2}Q_{\\alpha, \\beta,\\varepsilon}(f,g)=\\frac{-1}{\\varepsilon}\n",
    "\\begin{pmatrix}\n",
    "\\Delta(\\alpha) && \\pi_{\\varepsilon}\\\\\n",
    "\\pi^{T}_{\\varepsilon} && \\Delta(\\beta) \n",
    "\\end{pmatrix}\n",
    "\\ , \\ $ where $\\pi\\mathbb{1}_{m} = \\alpha,\\ \\pi^{T}\\mathbb{1}_{n}=\\beta,\\ $ and $\\Delta = diag: \\mathbb{R}^{n} \\rightarrow M_{n}(\\mathbb{R})$ is the linear operator mapping a vector  to a diagonal matrix  containing  this vector.\n",
    "\n",
    "\n",
    "This implies \n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\Delta(\\alpha) && \\pi_{\\varepsilon}\\\\\n",
    "\\pi^{T}_{\\varepsilon} && \\Delta(\\beta) \n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "\\mathbb{1}_{n}\\\\\n",
    "\\mathbb{1}_{m}\n",
    "\\end{pmatrix} = 0\\ ,\n",
    "$$\n",
    "that is,\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\mathbb{1}_{n}\\\\\n",
    "\\mathbb{1}_{m}\n",
    "\\end{pmatrix}\\in \\ker(\\nabla^{2}Q_{\\alpha, \\beta,\\varepsilon}(f,g))\\ .\n",
    "$$\n",
    "Hence, $\\nabla^{2}Q_{\\alpha, \\beta,\\varepsilon}(f,g)$ is singular. Therefore, on regularization we have the following Hessian\n",
    "$\n",
    "H_{reg} := \\nabla^{2}Q_{\\alpha, \\beta,\\varepsilon}(f,g)+\\lambda cc^{T}\\ ,\n",
    "$ \n",
    "where $c= \\begin{pmatrix}\\frac{\\mathbb{1}}{\\sqrt{n+m}}\\\\-\\frac{\\mathbb{1}}{\\sqrt{n+m}}\\end{pmatrix}\\in M_{(n+m),1}(\\mathbb{R})$.\n",
    "\n",
    "Now, at the $k^{th}$ iteration solve\n",
    "$\\nabla^{2}Q_{\\alpha, \\beta,\\varepsilon}(f,g)p_{k} = \\nabla Q_{\\alpha, \\beta,\\varepsilon}(f,g)$ to obtain the optimizing direction vector $p_{k}$ and then perform the Armijo condition to obtain the update step $\\alpha_{k}$ such that we have the update\n",
    "$$\n",
    "(f,g) \\leftarrow (f,g) + \\alpha_{k} p_{k}\\ .\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampednewton( epsilons, N, x, y, rho = 0.95, c = 0.05, iterations = 50 ):\n",
    "    print(\"Damped Newton... \")\n",
    "    print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "    dampedNewtonP=[]\n",
    "    results_dampedNewton  = []\n",
    "    times_dampedNewton    = []\n",
    "    Hessians_dampedNewton = []\n",
    "    #Cost matrix\n",
    "    C = distmat( x, y )\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    for eps in epsilons:\n",
    "        print(\"For epsilon = \"+str(eps)+\":\")     \n",
    "        #Kernel\n",
    "        K = np.exp( - C/eps )\n",
    "        f, g = a, b\n",
    "        print( \" |- Iterating\")  \n",
    "        start = time.time()\n",
    "        Optimizer = computational_OT.damped_Newton( K,\n",
    "                                                    a,\n",
    "                                                    b,\n",
    "                                                    f,\n",
    "                                                    g,\n",
    "                                                    eps,\n",
    "                                                    rho,\n",
    "                                                    c )\n",
    "        out = Optimizer._update(    max_iterations = iterations,\n",
    "                                    debug = False )\n",
    "        end = time.time()\n",
    "        if ( out != np.zeros(6) ).all():\n",
    "            results_dampedNewton.append( out )\n",
    "            times_dampedNewton.append( end - start )\n",
    "            print( \" |- Computing P\" )\n",
    "            print( \"\" )\n",
    "            u_opt = np.exp( out['potential_f']/eps )\n",
    "            K = np.exp( - C/eps )\n",
    "            v_opt =  np.exp( out['potential_g']/eps )\n",
    "            P_opt = GetP( u_opt, K, v_opt )\n",
    "            dampedNewtonP.append( P_opt )\n",
    "            print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "            mat  = - eps * Optimizer.Hessian\n",
    "            diag = 1/np.sqrt( np.concatenate( ( a, b ), axis = None ) )\n",
    "            mat = diag[:,None] * mat * diag[None,:]\n",
    "            Hessians_dampedNewton.append( mat )\n",
    "        else:\n",
    "            epsilons.remove( eps )\n",
    "    # end for\n",
    "    return {\n",
    "        'results_list': results_dampedNewton,\n",
    "        'time_stamps' : times_dampedNewton,\n",
    "        'Ps'          : dampedNewtonP,\n",
    "        'Hessians'    : Hessians_dampedNewton \n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Damped Newton with preconditioning iteration function\n",
    "Here we perform dual damped Newton with preconditioning. Here we consider $t$ eigenvalues of the Hessian that we want to move to one and form the following preconditioning matrix using the corresponding eigenvectors,\n",
    "$$\n",
    "P = \\left(I_{n+m}-\\sum_{i-1}^{t}\\left(1 - \\frac{1}{\\sqrt{\\lambda_{i}}}\\right)y_{i}y_{i}^{T}\\right)\\ ,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "y_{i} \\in \\ker\\left(\\nabla^{2}_{f}Q_{\\alpha, \\beta, \\varepsilon}(f)-\\lambda_{i}I_{n}\\right),\\ \\forall i= 1,\\dots,k\\ ,\n",
    "$$\n",
    " are orthonormal.\n",
    "\n",
    "Now, at the $k^{th}$ iteration we solve the following equation:\n",
    "$$\n",
    "(P\\nabla^{2}Q_{\\alpha, \\beta, \\varepsilon}(f)P)(Pp_{k})=P\\nabla Q_{\\alpha, \\beta, \\varepsilon}(f)\\ ,\n",
    "$$\n",
    "using iterative inversion methods such as \"Conjugate gradient\" and \"GMRES\" to get the ascent direction $p_{k}$, following which we use the Armijo condition to obtain the ascent step size $\\alpha_{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, rho = 0.95, c = 0.05,  iterations = 500, iter_inv = 30, optimizer = 'cg', version = None, debug = False):\n",
    "    print(\"Damped Newton with preconditioning... \")\n",
    "    print( \"Doing for (\",N[0], N[1],\").\" )\n",
    "    reset_starting_point = True\n",
    "    final_modified_Hessians = []\n",
    "    dampedNewtonwithprecondP = []\n",
    "    results_dampedNewtonwithprecond  = []\n",
    "    times_dampedNewtonwithprecond    = []\n",
    "    # Cost matrix\n",
    "    C = distmat( x, y )\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    f, g = None, None\n",
    "    for eps in epsilons:\n",
    "        print( \"For epsilon = \"+str(eps)+\":\" )    \n",
    "        #Kernel\n",
    "        K = np.exp( - C/eps )\n",
    "        if (f is None) or (g is None): \n",
    "            f, g = a, b\n",
    "        print( \" |- Iterating\" )  \n",
    "        start = time.time()\n",
    "        Optimizer = computational_OT.damped_Newton_with_preconditioning(    K,\n",
    "                                                                            a,\n",
    "                                                                            b,\n",
    "                                                                            f,\n",
    "                                                                            g,\n",
    "                                                                            eps,\n",
    "                                                                            rho,\n",
    "                                                                            c,\n",
    "                                                                            null_vector,\n",
    "                                                                            precond_vectors[:] )\n",
    "        out = Optimizer._update(    max_iterations = iterations,\n",
    "                                    iterative_inversion = iter_inv,\n",
    "                                    version = version,\n",
    "                                    debug = debug,\n",
    "                                    optType = optimizer )\n",
    "        results_dampedNewtonwithprecond.append( out )\n",
    "        end = time.time()\n",
    "        times_dampedNewtonwithprecond.append( end - start )\n",
    "        print( \" |- Computing P\" )\n",
    "        print( \"\" )\n",
    "        u_opt = np.exp( out['potential_f']/eps )\n",
    "        K = np.exp( - C/eps )\n",
    "        v_opt =  np.exp( out['potential_g']/eps )\n",
    "        P_opt = GetP( u_opt, K, v_opt )\n",
    "        dampedNewtonwithprecondP.append( P_opt )   \n",
    "        if not reset_starting_point:\n",
    "            f = Optimizer.x[:a.shape[0]]\n",
    "            g = Optimizer.x[a.shape[0]:]\n",
    "        final_modified_Hessians.append( Optimizer.modified_Hessian )\n",
    "    # end for\n",
    "    return {\n",
    "        'results_list': results_dampedNewtonwithprecond,\n",
    "        'time_stamps' : times_dampedNewtonwithprecond,\n",
    "        'Ps'          : dampedNewtonwithprecondP,\n",
    "        'Hessians'    : final_modified_Hessians \n",
    "    }    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison for Data size 400 and 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [ 400, 500 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x     = np.random.rand( 2, N[0] ) - 0.5\n",
    "theta = 2 * np.pi * np.random.rand( 1, N[1] )\n",
    "r     = 0.8 + .2 * np.random.rand( 1, N[1] )\n",
    "y     = np.vstack( ( r * np.cos(theta), r * np.sin(theta) ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [  0.03, 0.001, 0.0009, 0.00084 ]\n",
    "results_sinkhorn = sinkhorn( epsilons, N, x, y, iterations = 20000 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range(len(results_sinkhorn['results_list'])):\n",
    "  error = np.asarray( results_sinkhorn['results_list'][i]['error_a'] ) + np.asarray( results_sinkhorn['results_list'][i]['error_b'] ) \n",
    "  plt.plot( error, label = 'Sinkhorn for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ConvergenceSinkhornvaryingepsilon.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Damped Newton without Preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [  0.5, 0.03, 0.02 ]\n",
    "results_dampedNewton = dampednewton( epsilons, N, x, y )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewton['results_list'])):\n",
    "  error = np.asarray( results_dampedNewton['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewton['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig(\"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithoutPrecond.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective function plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"Objective Function\" )\n",
    "for i in range(len(results_dampedNewton['results_list'])):\n",
    "  plt.plot( np.asarray( results_dampedNewton['results_list'][i]['objective_values'] ), label = 'Damped Newton for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Objective value\" )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ObjectiveDampedNewtonwithoutPrecond.pdf\", format = 'pdf' )\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ascent step-size plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 ),\n",
    "plt.title( \"Alpha\" )\n",
    "for i in range(len(results_dampedNewton['results_list'])):\n",
    "  plt.plot( np.asarray( results_dampedNewton['results_list'][i]['linesearch_steps'] ), label = 'Damped Newton for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Alpha in log-scale\" )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/AlphaDampedNewtonwithoutPrecond.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting spectrum as a function of $\\varepsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition( mat ):\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort( eig )\n",
    "    eig = eig[ sorting_indices ]\n",
    "    v   = v[ : , sorting_indices ]\n",
    "    print( \"List of smallest eigenvalues: \", eig[ : 10 ] )\n",
    "    print( \"List of largest  eigenvalues: \", eig[ - 10 : ] )\n",
    "    return eig, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range(len(epsilons)):\n",
    "    eps = epsilons[i]\n",
    "    print(\"Spectral statistics of Hessian for epsilon = \"+str(eps))\n",
    "    ev = spectral_decomposition( results_dampedNewton['Hessians'][i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title(\"Histogram of eigenvalues.\")\n",
    "for i in range(len(epsilons)):\n",
    "    ax[i].hist( eigs[i], 50)\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]))\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.5 )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/eigenhistunstabilizedDampedNewtonwithoutPrecond.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preconditioners( num_eigs, modified_Hessian, ansatz = True ):\n",
    "    # Diagonalize\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh( modified_Hessian )\n",
    "    sorting_indices = np.argsort( eigenvalues )\n",
    "    eigenvalues  = eigenvalues[ sorting_indices ]\n",
    "    eigenvectors = eigenvectors[ : , sorting_indices ]\n",
    "    # Form null vector\n",
    "    if not ansatz:\n",
    "        null_vector = eigenvectors[ : , 0 ]\n",
    "    else:\n",
    "        null_vector = np.hstack( ( np.ones(N[0]), - np.ones(N[1]) ) )\n",
    "        norm = np.sqrt( N[0] + N[1] )\n",
    "        null_vector = null_vector/norm\n",
    "    # Form other vectors (only 13)\n",
    "    _, m = eigenvectors.shape\n",
    "    indices = []\n",
    "    for i in range(num_eigs//2):\n",
    "        indices.append( m - i - 2 )\n",
    "        indices.append( i + 1 )\n",
    "    # end fdr\n",
    "    if num_eigs%2 != 0:\n",
    "        indices.append( m - 1 - ( num_eigs//2 ) )\n",
    "   \n",
    "    precond_vectors = eigenvectors[ : , indices ]\n",
    "    precond_vectors = []\n",
    "    for index in indices:\n",
    "        precond_vectors.append( eigenvectors[:,index] )\n",
    "    # end for\n",
    "    return null_vector, precond_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 13\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, results_dampedNewton['Hessians'][-1], ansatz = False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Damped Newton with Preconditioning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.001 , 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 50, version = None, iter_inv = -1, rho = 0.95 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20,7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum of the Hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range(len(epsilons)):\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "    ev = spectral_decomposition( results_dampedNewtonwithprecond['Hessians'][i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n",
    "# end for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots( figsize = ( 5, 12 ), nrows = len(epsilons), ncols = 1, sharey = True )\n",
    "plt.title(\"Histogram of eigenvalues.\")\n",
    "for i in range(len(epsilons)):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]))\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "# end for\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.3 )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/eigenhistunstabilizedDampedNewtonwithPrecond.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative inversion = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.001, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 2, rho = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_5itv2.pdf\", format = 'pdf')\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 2, rho = 0.7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_7itv2.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 2, rho = 0.9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' ) \n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_9itv2.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Inversion = 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 5, rho = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_5itv5.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 5, rho = 0.7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_7itv5.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 5, rho = 0.9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_9itv5.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Inversion = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 10, rho = 0.5 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_5itv10.pdf\", format = 'pdf' ) \n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 10, rho = 0.7 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray(results_dampedNewtonwithprecond['results_list'][i]['error_a']) + np.asarray(results_dampedNewtonwithprecond['results_list'][i]['error_b'])\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_7itv10.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition( epsilons, N, x, y, null_vector, precond_vectors, iterations = 500,iter_inv = 10, rho = 0.9 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" ) \n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_9itv10.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rho = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = [ 0.5, 0.03, 0.02, 0.00084 ] \n",
    "results_dampedNewtonwithprecond = dampednewtonprecondition(  epsilons, N, x, y, null_vector, precond_vectors, iterations = 500, iter_inv = 10, rho = 0.95 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range(len(results_dampedNewtonwithprecond['results_list'])):\n",
    "  error = np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_a'] ) + np.asarray( results_dampedNewtonwithprecond['results_list'][i]['error_b'] )\n",
    "  plt.plot( error, label = 'Damped Newton with preconditioning for $\\epsilon = $'+ str(epsilons[i]), linewidth = 2 )\n",
    "# end for\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()  \n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/SinkhornvsDampedNewton_images/ErrorDampedNewtonwithPrecondrho0_95itv10.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
