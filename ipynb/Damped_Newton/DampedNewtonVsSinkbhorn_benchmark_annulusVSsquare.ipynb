{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we benchmark the performance of Sinkhon vs damped Newton for different distance functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path_to_new_folder = \"../Images\"\n",
    "os.makedirs(relative_path_to_new_folder, exist_ok=True)\n",
    "if not os.path.isdir('../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images'):\n",
    "    os.makedirs('../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_norms(x,y,p):\n",
    "   \n",
    "   if p == 1:\n",
    "      \n",
    "      return  abs(np.sum(x,0)[:,None]-np.sum(y,0)[None,:])  \n",
    "   \n",
    "   elif p == 2:\n",
    "      return  np.sum( x**2,0 )[:,None] + np.sum( y**2,0 )[None,:] - 2*x.transpose().dot(y)\n",
    "   \n",
    "   elif p == 4:\n",
    "    return np.sum( x**4,0 )[:,None] + np.sum( y**4,0 )[None,:] + 4*(x**3).transpose().dot(y) - 4*x.transpose().dot(y**3) + 6*(x**2).transpose().dot(y**2)\n",
    "\n",
    "   elif p == 'inf':\n",
    "      return np.maximum(abs(x[0,:][:,None]-y[0,:][None,:]),abs(x[1,:][:,None] - y[1:][None:]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat(x,y):\n",
    "    return np.sum( x**2,0 )[:,None] + np.sum( y**2,0 )[None,:] - 2*x.transpose().dot(y)\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum( a )\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP(u,K,v):\n",
    "    return u[:,None]*K*v[None,:]\n",
    "\n",
    "def plotp(x, col,plt, scale=200, edgecolors=\"k\"):\n",
    "  return plt.scatter( x[0,:], x[1,:], s=scale, edgecolors=edgecolors,  c=col, cmap='plasma', linewidths=2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import computational_OT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition(mat):\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort(eig)\n",
    "    eig = eig[sorting_indices]\n",
    "    v   = v[:, sorting_indices]\n",
    "    \n",
    "    print( \"List of smallest eigenvalues: \", eig[:10])\n",
    "    print( \"List of largest  eigenvalues: \", eig[-10:])\n",
    "\n",
    "    return eig,v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preconditioners( num_eigs,modified_Hessian, N, ansatz=True ):\n",
    "    # Diagonalize\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh( modified_Hessian )\n",
    "    sorting_indices = np.argsort( eigenvalues )\n",
    "    eigenvalues  = eigenvalues[sorting_indices]\n",
    "    eigenvectors = eigenvectors[:, sorting_indices]\n",
    "    # Form null vector\n",
    "    if not ansatz:\n",
    "        null_vector = eigenvectors[:, 0]\n",
    "    else:\n",
    "        null_vector = np.hstack( (np.ones(N[0]), -np.ones(N[1])) )\n",
    "        norm = np.sqrt( N[0] + N[1] )\n",
    "        null_vector = null_vector/norm\n",
    "    # Form other vectors (only 13)\n",
    "    n,m = eigenvectors.shape\n",
    "    indices=[]\n",
    "    for i in range(num_eigs//2):\n",
    "        indices.append(m-i-2)\n",
    "        indices.append(i+1)\n",
    "    if num_eigs%2!=0:\n",
    "        indices.append(m-1-(num_eigs//2))\n",
    "   \n",
    "    precond_vectors = eigenvectors[:, indices ]\n",
    "    precond_vectors = []\n",
    "    for index in indices:\n",
    "        precond_vectors.append( eigenvectors[:,index] )\n",
    "    #\n",
    "    return null_vector, precond_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = [ 1000,1200 ]\n",
    "epsilons = [ 0.1,0.09,0.05,0.03 ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand( 2,N[0] ) - 0.5\n",
    "theta = 2*np.pi*np.random.rand( 1,N[1] )\n",
    "r = 0.8+.2*np.random.rand( 1,N[1] )\n",
    "y = np.vstack( ( r*np.cos( theta ),r*np.sin( theta ) ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. L-1 norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C = p_norms(x,y,2)\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print( \"Doing for (\",N[0],N[1],\") and epsilon = \" +str(eps)+ \" .\" )\n",
    "  print( \" |- Iterating\" )\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn( K,a,b,u,v,eps)\n",
    "  out = Optimizer._update(maxiter=10000)\n",
    "  results_Sinkhorn.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append( end-start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn) ):\n",
    "  error=np.asarray( results_Sinkhorn[i]['error_a'] )+np.asarray( results_Sinkhorn[i]['error_b'] )\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ConvergenceSinkhornvaryingepsilonL1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Damped Newton\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    #Cost matrix\n",
    "    C = p_norms(x,y,1)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "    f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton( K,a,b,f,g,eps,rho,c )\n",
    "    out = Optimizer._update( maxiter=50 )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append( end-start )\n",
    "    print( \" |- Computing P\" )\n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon=\"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(5,12), nrows=len(epsilons), ncols=1, sharey=True)\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "plt.subplots_adjust( wspace=0,hspace=0 )\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/eigenhistunstabilizedL1.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_DampedNewton[-1],N, ansatz=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons = [ 0.3 ]\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon=\"+str(eps)+\":\" )    \n",
    "    # Cost matrix\n",
    "    C = p_norms(x,y,1)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_With_Preconditioner( K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter=50, iterative_inversion=30, version=None,debug=False,optType='cg' )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\" )\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "\n",
    "for i in range( len(results_DampedNewton) ):\n",
    "  error = np.asarray( results_DampedNewton[i]['error_a'] )+np.asarray( results_DampedNewton[i]['error_b'] )\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ErrorLinesearchNewton_final_cgL1.png\" )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. L-2 norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C = p_norms(x,y,2)\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print( \"Doing for (\",N[0],N[1],\") and epsilon = \" +str(eps)+ \" .\" )\n",
    "  print( \" |- Iterating\" )\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn( K,a,b,u,v,eps)\n",
    "  out = Optimizer._update(maxiter=10000)\n",
    "  results_Sinkhorn.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append( end-start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn) ):\n",
    "  error=np.asarray( results_Sinkhorn[i]['error_a'] )+np.asarray( results_Sinkhorn[i]['error_b'] )\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ConvergenceSinkhornvaryingepsilonL2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    #Cost matrix\n",
    "    C = p_norms(x,y,2)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "    f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton( K,a,b,f,g,eps,rho,c )\n",
    "    out = Optimizer._update( maxiter=50 )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append( end-start )\n",
    "    print( \" |- Computing P\" )\n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon=\"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(24,3),nrows=1, ncols=len(epsilons), sharey=True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "plt.subplots_adjust( wspace=0,hspace=0 )\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/eigenhistunstabilizedL2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_DampedNewton[-1],N, ansatz=False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons = [ 0.3 ]\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon=\"+str(eps)+\":\" )    \n",
    "    # Cost matrix\n",
    "    C = p_norms(x,y,2)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_With_Preconditioner( K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter=50, iterative_inversion=30, version=None,debug=False,optType='cg' )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\" )\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "\n",
    "for i in range( len(results_DampedNewton) ):\n",
    "  error = np.asarray( results_DampedNewton[i]['error_a'] )+np.asarray( results_DampedNewton[i]['error_b'] )\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ErrorLinesearchNewton_final_cgL2.png\" )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. L4-norm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C = p_norms(x,y,4)\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print( \"Doing for (\",N[0],N[1],\") and epsilon = \" +str(eps)+ \" .\" )\n",
    "  print( \" |- Iterating\" )\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn( K,a,b,u,v,eps)\n",
    "  out = Optimizer._update(maxiter=10000)\n",
    "  results_Sinkhorn.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append( end-start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn) ):\n",
    "  error=np.asarray( results_Sinkhorn[i]['error_a'] )+np.asarray( results_Sinkhorn[i]['error_b'] )\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ConvergenceSinkhornvaryingepsilonL4.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    #Cost matrix\n",
    "    C = p_norms(x,y,4)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "    f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton( K,a,b,f,g,eps,rho,c )\n",
    "    out = Optimizer._update( maxiter=50 )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append( end-start )\n",
    "    print( \" |- Computing P\" )\n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon=\"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(24,3),nrows=1, ncols=len(epsilons), sharey=True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    if not np.isnan(eigs[i]).any():\n",
    "        ax[i].hist( eigs[i], 50 )\n",
    "        ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "        ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "        ax[i].set_yscale( \"log\" )\n",
    "    \n",
    "    else:\n",
    "        print(\"The eigenvalues for \"+str(epsilons[i])+ \" contains Nans.\")\n",
    "plt.subplots_adjust( wspace=0,hspace=0 )\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/eigenhistunstabilizedL2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_DampedNewton[-1],N, ansatz=False )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons = [ 0.3 ]\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon=\"+str(eps)+\":\" )    \n",
    "    # Cost matrix\n",
    "    C = p_norms(x,y,4)\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_With_Preconditioner( K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter=50, iterative_inversion=30, version=None,debug=False,optType='cg' )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\" )\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "\n",
    "for i in range( len(results_DampedNewton) ):\n",
    "  error = np.asarray( results_DampedNewton[i]['error_a'] )+np.asarray( results_DampedNewton[i]['error_b'] )\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ErrorLinesearchNewton_final_cgL2.png\" )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. L-infinity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C = p_norms(x,y,'inf')\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print( \"Doing for (\",N[0],N[1],\") and epsilon = \" +str(eps)+ \" .\" )\n",
    "  print( \" |- Iterating\" )\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn( K,a,b,u,v,eps)\n",
    "  out = Optimizer._update(maxiter=10000)\n",
    "  results_Sinkhorn.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append( end-start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn) ):\n",
    "  error=np.asarray( results_Sinkhorn[i]['error_a'] )+np.asarray( results_Sinkhorn[i]['error_b'] )\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ConvergenceSinkhornvaryingepsilonL4.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    #Cost matrix\n",
    "    C = p_norms(x,y,'inf')\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "    f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton( K,a,b,f,g,eps,rho,c )\n",
    "    out = Optimizer._update( maxiter=50 )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append( end-start )\n",
    "    print( \" |- Computing P\" )\n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon=\"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(24,3),nrows=1, ncols=len(epsilons), sharey=True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "plt.subplots_adjust( wspace=0,hspace=0 )\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/eigenhistunstabilizedL2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_DampedNewton[-1],N, ansatz=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons = [ 0.3 ]\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon=\"+str(eps)+\":\" )    \n",
    "    # Cost matrix\n",
    "    C = p_norms(x,y,'inf')\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_With_Preconditioner( K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter=50, iterative_inversion=30, version=None,debug=False,optType='cg' )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\" )\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "\n",
    "for i in range( len(results_DampedNewton) ):\n",
    "  error = np.asarray( results_DampedNewton[i]['error_a'] )+np.asarray( results_DampedNewton[i]['error_b'] )\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ErrorLinesearchNewton_final_cgL2.png\" )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. 1-cosine similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP=[]\n",
    "results_Sinkhorn=[]\n",
    "times_Sinkhorn=[]\n",
    "for eps in epsilons:\n",
    "\n",
    "  \n",
    "  #Cost matrix\n",
    "  C =1- (x.transpose().dot(y))/(np.linalg.norm(x,2)*np.linalg.norm(y,2))\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[0]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[1]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "  print( \"Doing for (\",N[0],N[1],\") and epsilon = \" +str(eps)+ \" .\" )\n",
    "  print( \" |- Iterating\" )\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn( K,a,b,u,v,eps)\n",
    "  out = Optimizer._update(maxiter=10000)\n",
    "  results_Sinkhorn.append( out )\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append( end-start )\n",
    "  print( \" |- Computing P\" )\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure( figsize = (20,7) )\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title( \"$||P1 -a||_1+||P1 -b||_1$\" )\n",
    "for i in range( len(results_Sinkhorn) ):\n",
    "  error=np.asarray( results_Sinkhorn[i]['error_a'] )+np.asarray( results_Sinkhorn[i]['error_b'] )\n",
    "  plt.plot( error,label='Sinkhorn for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ConvergenceSinkhornvaryingepsilonL4.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton without preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "Hessians_DampedNewton = []\n",
    "\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    #Cost matrix\n",
    "    C =1- (x.transpose().dot(y))/(np.linalg.norm(x,2)*np.linalg.norm(y,2))\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones( N[0] ) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones( N[1] ) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "    f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton( K,a,b,f,g,eps,rho,c )\n",
    "    out = Optimizer._update( maxiter=50 )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append( end-start )\n",
    "    print( \" |- Computing P\" )\n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n\" )\n",
    "\n",
    "    mat  = -eps*Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( np.vstack( (a,b) ) ).flatten()\n",
    "    mat = diag[:,None]*mat*diag[None,:]\n",
    "    Hessians_DampedNewton.append( mat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len(epsilons) ) :\n",
    "    eps = epsilons[i]\n",
    "    print( \"Spectral statistics of Hessian for epsilon=\"+str(eps) )\n",
    "    ev = spectral_decomposition( Hessians_DampedNewton[i] )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots( figsize=(24,3),nrows=1, ncols=len(epsilons), sharey=True )\n",
    "plt.title( \"Histogram of eigenvalues.\" )\n",
    "for i in range( len(epsilons) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \"+str(epsilons[i]) )\n",
    "    ax[i].set_xlabel( \"Eigenvalues\" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "plt.subplots_adjust( wspace=0,hspace=0 )\n",
    "plt.savefig(\"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/eigenhistunstabilizedL2.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Damped Newton with preconditioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 10\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs, Hessians_DampedNewton[-1],N, ansatz=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "c = 0.05\n",
    "reset_starting_point = True\n",
    "final_modified_Hessians = []\n",
    "DampedNewtonP = []\n",
    "results_DampedNewton  = []\n",
    "times_DampedNewton    = []\n",
    "\n",
    "#epsilons = [ 0.3 ]\n",
    "f, g = None, None\n",
    "for eps in epsilons:\n",
    "    # Line Search\n",
    "    print( \"Damped Newton for epsilon=\"+str(eps)+\":\" )    \n",
    "    # Cost matrix\n",
    "    C =1- (x.transpose().dot(y))/(np.linalg.norm(x,2)*np.linalg.norm(y,2))\n",
    "\n",
    "    # a and b\n",
    "    a = normalize( np.ones(N[0]) )\n",
    "    a = a.reshape( a.shape[0],-1 )\n",
    "    b = normalize( np.ones(N[1]) )\n",
    "    b = b.reshape( b.shape[0],-1 )\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "    if (f is None) or (g is None): \n",
    "        f,g = a,b\n",
    "\n",
    "    print( \"Doing for (\",N[0],N[1],\").\" )\n",
    "    print( \" |- Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_With_Preconditioner( K,a,b,f,g,eps,rho,c,null_vector,precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter=50, iterative_inversion=30, version=None,debug=False,optType='cg' )\n",
    "    results_DampedNewton.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton.append(end-start)\n",
    "    print( \" |- Computing P\" )\n",
    "\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "        # f = f.reshape( f.shape[0], -1)\n",
    "        # g = g.reshape( g.shape[0], -1)\n",
    "    \n",
    "    DampedNewtonP.append( GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = (20,7) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "\n",
    "for i in range( len(results_DampedNewton) ):\n",
    "  error = np.asarray( results_DampedNewton[i]['error_a'] )+np.asarray( results_DampedNewton[i]['error_b'] )\n",
    "  plt.plot( error,label='Damped Newton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Error in log-scale\" )\n",
    "plt.legend()\n",
    "plt.yscale( 'log' )\n",
    "plt.savefig( \"../Images/DampedNewtonVsSinkhorn_benchmark_annulusVSsquare_images/ErrorLinesearchNewton_final_cgL2.png\" )\n",
    "plt.show()\n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
