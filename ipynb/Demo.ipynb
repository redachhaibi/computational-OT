{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this notebook we look at the performance of various optimization algorithms namely: linear optimization, Sinkhorn, gradient ascent, line search and L-BFGS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "import pylab as pyl\n",
    "import time\n",
    "import cvxpy as cp\n",
    "from numpy import linalg as Lin\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import style\n",
    "from sklearn import datasets\n",
    "import computational_OT\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir('Images'):\n",
    "    os.makedirs('Images')\n",
    "if not os.path.isdir('Images/Demo_images'):\n",
    "    os.makedirs('Images/Demo_images')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-tlrzQ3chK2S"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHDEEFt3Kvkk"
   },
   "outputs": [],
   "source": [
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat(x,y):\n",
    "    return np.sum(x**2,0)[:,None] + np.sum(y**2,0)[None,:] - 2*x.transpose().dot(y)\n",
    "\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum( a )\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP(u,K,v):\n",
    "    return u[:,None]*K*v[None,:]\n",
    "\n",
    "def plotp(plt, x, col, scale=200, edgecolors=\"k\"):\n",
    "  return plt.scatter(x[0,:], x[1,:], s=scale, edgecolors=edgecolors,  c=col, cmap='plasma', linewidths=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OBXdvMUNhSU5"
   },
   "source": [
    "# Annulus vs Square"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JRHkp03xbECd"
   },
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TkZ9gSGBjEdJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6uU8x1qhuo2"
   },
   "outputs": [],
   "source": [
    "def randomsampledata(N):\n",
    "  x = []\n",
    "  y = []\n",
    "  N=np.sort(N)\n",
    "  for i in range(len(N)):\n",
    "    x.append(np.random.rand(2,N[i])-0.5)\n",
    "    theta= 2*np.pi*np.random.rand(1,N[i])\n",
    "    r = 0.8+0.2*np.random.rand(1,N[i])\n",
    "    y.append(np.vstack((np.cos(theta)*r,np.sin(theta)*r)))\n",
    "  \n",
    "  return x,y,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUO4f-EYLx2R"
   },
   "outputs": [],
   "source": [
    "N = [ 200,400,600,800,1000 ]\n",
    "x,y,N = randomsampledata(N)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KijJh0En1oxK"
   },
   "source": [
    "### I. Linear Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "SFad1Bvky0yZ",
    "outputId": "0c879d5d-8d0c-4787-8dbb-8a55f6ecce84"
   },
   "outputs": [],
   "source": [
    "times_linearOpt = []\n",
    "LinearP = []\n",
    "for i in range(len(N)):\n",
    "  xi,yi = x[i],y[i]\n",
    "  #Cost matrix\n",
    "  C = distmat(xi,yi)\n",
    "\n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[i]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[i]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "\n",
    "\n",
    "  plt.figure(figsize=(5,5))\n",
    "\n",
    "  plotp(plt,xi, col='b')\n",
    "  plotp(plt,yi, col='r')\n",
    "\n",
    "  plt.axis(\"off\")\n",
    "  plt.xlim(np.min(yi[0,:])-.1,np.max(yi[0,:])+.1)\n",
    "  plt.ylim(np.min(yi[1,:])-.1,np.max(yi[1,:])+.1)\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  print(\"Doing for \",N[i])\n",
    "  print( \" |- Iterating\")\n",
    "  ### Linear Optimization\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.LinearOptimize(N[i],N[i],a,b,C)\n",
    "  print( \" |- Computing P\")\n",
    "  print( \"\" )\n",
    "  P_linear = Optimizer.solve()\n",
    "  LinearP.append(P_linear.value)\n",
    "  end = time.time()\n",
    "  times_linearOpt.append(end-start)\n",
    "\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "XI1siOVE1t0l"
   },
   "source": [
    "### II. Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpF7nb14Kz1y",
    "outputId": "235f0b6f-0bd1-40e1-c1d4-8c283e738af1"
   },
   "outputs": [],
   "source": [
    "# Sinkhorn\n",
    "print(\"Sinkhorn.... \")\n",
    "SinkhornP = []\n",
    "results_Sinkhorn = []\n",
    "times_Sinkhorn = []\n",
    "Pmatrix_dist_linVSsinkhorn = []\n",
    "for i in range(len(N)):\n",
    "\n",
    "  \n",
    "  xi,yi = x[i],y[i]\n",
    "  #Cost matrix\n",
    "  C = distmat(xi,yi)\n",
    "  \n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[i]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[i]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "  \n",
    "  #Epsilon\n",
    "  epsilon = .06\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/epsilon)\n",
    "\n",
    "\n",
    "  print(\"Doing for \",N[i])\n",
    "  print( \" |- Iterating\")\n",
    "\n",
    "  #Inflating\n",
    "  u = a\n",
    "  v = b\n",
    "\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Sinkhorn(K,a,b,u,v,epsilon)\n",
    "  out = Optimizer._update()\n",
    "  results_Sinkhorn.append(out)\n",
    "  end = time.time()\n",
    "  times_Sinkhorn.append(end-start)\n",
    "  print( \" |- Computing P\")\n",
    "  print( \"\" )\n",
    "  SinkhornP.append(GetP(np.exp(out['potential_f']/epsilon),K,np.exp(out['potential_g']/epsilon)))\n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "HIvJCYZEiBjH"
   },
   "source": [
    "##### Convergence plot for Sinkhorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "8glqdQVC3C7W",
    "outputId": "51413c80-637c-4fc2-b587-b9e6c86efe41"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1$\")\n",
    "for result in results_Sinkhorn:\n",
    "  plt.plot( np.asarray(result['error_a']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.title(\"$||P^T 1 -b||_1$\")\n",
    "for result in results_Sinkhorn:\n",
    "  plt.plot( np.asarray(result['error_b']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.savefig(\"Images/Demo_images/ConvergenceSink.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SbwY4W2eIysN"
   },
   "source": [
    "##### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "T7aD_v82Iod_",
    "outputId": "8cc5f837-29b5-4162-c560-bb6e0724290e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "\n",
    "for result in results_Sinkhorn:\n",
    "  plt.plot(np.asarray(result['objectives']).flatten(), linewidth = 2)\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dPgMmsHIZA3G"
   },
   "source": [
    "### III. Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U01CNug6ZAil",
    "outputId": "f04af0e8-1e7d-4ee8-cf0d-a0e06e25aa7b"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "\n",
    "GradientAscentP = []\n",
    "results_Gradient_ascent = []\n",
    "times_Gradient_ascent = []\n",
    "Pmatrix_dist_linVSgradientascent = []\n",
    "Pmatrix_dist_sinkhornVSgradientascent = []\n",
    "\n",
    "# Gradient ascent\n",
    "print(\"Gradient ascent....\")\n",
    "results_Gradient_ascent = []\n",
    "times_Gradient_ascent = []\n",
    "for i in range(len(N)):\n",
    "\n",
    "  xi,yi = x[i],y[i]\n",
    "  #Cost matrix\n",
    "  C = distmat(xi,yi)\n",
    "\n",
    "  # a and b\n",
    "  a = normalize(np.ones(N[i]))\n",
    "  a = a.reshape(a.shape[0],-1)\n",
    "  b = normalize(np.ones(N[i]))\n",
    "  b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "  #Epsilon\n",
    "  epsilon = .06\n",
    "\n",
    "  #Kernel\n",
    "  K = np.exp(-C/epsilon)\n",
    "  \n",
    "  f,g = a,b\n",
    "  \n",
    "\n",
    "\n",
    "  print(\"Doing for \",N[i])\n",
    "  print( \" |- Iterating\")\n",
    "  start = time.time()\n",
    "  Optimizer = computational_OT.Gradient_Ascent(K,a,b,f,g,epsilon,learning_rate)\n",
    "  out = Optimizer._update()\n",
    "  results_Gradient_ascent.append(out)\n",
    "  end = time.time()\n",
    "  times_Gradient_ascent.append(end-start)\n",
    "  print( \" |- Computing P\")\n",
    "  print( \"\" )\n",
    "  GradientAscentP.append(GetP(np.exp(out['potential_f']/epsilon),K,np.exp(out['potential_g']/epsilon)))\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "utM3LQZtiJ1O"
   },
   "source": [
    "##### Convergence plot for Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "pgeNPq_a3CnB",
    "outputId": "30f58ecf-2e93-419a-a972-7e097576cb5d"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1$\")\n",
    "\n",
    "for result in results_Gradient_ascent:\n",
    "  plt.plot(np.asarray(result['error_a']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.title(\"$||P^T 1 -b||_1$\")\n",
    "for result in results_Gradient_ascent:\n",
    "  plt.plot(np.asarray(result['error_b']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.savefig(\"Images/Demo_images/ConvergenceGrad.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "dn9Ed-_2JOGZ"
   },
   "source": [
    "##### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "nePA5WXKJJ49",
    "outputId": "86f8fae9-9776-4571-e622-4b0b452e28f4"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "\n",
    "for result in results_Gradient_ascent:\n",
    "  plt.plot(np.asarray(result['objectives']).flatten(), linewidth = 2)\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "0WIBcjX9tSs6"
   },
   "source": [
    "### IV. Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQCyZn8_eZmU",
    "outputId": "1ec9d4f8-4e3a-4de4-9df2-2c2032a65975"
   },
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "rho_inc = 1.5\n",
    "c1 = 0.05\n",
    "c2 = 0.9\n",
    "initial_alpha = 1\n",
    "\n",
    "LineSearchP = []\n",
    "results_LineSearch = []\n",
    "times_LineSearch = []\n",
    "Pmatrix_dist_linVSLineSearchP = []\n",
    "Pmatrix_dist_sinkhornVSLineSearchP = []\n",
    "\n",
    "Pmatrix_dist_GradientAscentVSLineSearchP = []\n",
    "\n",
    "\n",
    "# Line Search\n",
    "print(\"Line Search....\")\n",
    "for i in range(len(N)):\n",
    "\n",
    "      xi,yi = x[i],y[i]\n",
    "      #Cost matrix\n",
    "      C = distmat(xi,yi)\n",
    "\n",
    "      # a and b\n",
    "      a = normalize(np.ones(N[i]))\n",
    "      a = a.reshape(a.shape[0],-1)\n",
    "      b = normalize(np.ones(N[i]))\n",
    "      b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "      #Epsilon\n",
    "      epsilon = .06\n",
    "\n",
    "      #Kernel\n",
    "      K = np.exp(-C/epsilon)\n",
    "\n",
    "\n",
    "      f,g = a,b\n",
    "              \n",
    "\n",
    "      print(\"Doing for \",N[i])\n",
    "      print( \" |- Iterating\")\n",
    "      start = time.time()\n",
    "      Optimizer = computational_OT.LineSearch(K,a,b,f,g,epsilon,rho,rho_inc,c1,c2,initial_alpha)\n",
    "      out = Optimizer._update()\n",
    "      results_LineSearch.append(out)\n",
    "      end = time.time()\n",
    "      times_LineSearch.append(end-start)\n",
    "      print( \" |- Computing P\")\n",
    "      print( \"\" )\n",
    "      LineSearchP.append(GetP(np.exp(out['potential_f']/epsilon),K,np.exp(out['potential_g']/epsilon)))\n",
    "\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convergence plot for Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "SGAUKWmFZTLj",
    "outputId": "3750281b-f3d7-4f3f-cce9-acdc2b8eecd0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1$\")\n",
    "\n",
    "for result in results_LineSearch:\n",
    "  plt.plot(np.asarray(result['error_a']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.title(\"$||P^T 1 -b||_1$\")\n",
    "for result in results_LineSearch:\n",
    "  plt.plot(np.asarray(result['error_b']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.savefig(\"Images/Demo_images/ConvergenceLineSearch.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "RWs5fDjGeZyb",
    "outputId": "41f894e0-ba8b-41ed-e06e-05278955538c"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "\n",
    "for result in results_LineSearch:\n",
    "  plt.plot(np.asarray(result['objectives']), linewidth = 2)\n",
    "#plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Alpha plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "im-fEYZ-pw44",
    "outputId": "28803063-395b-4d99-c481-9a64130faa20"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for result in results_LineSearch:\n",
    "  plt.plot(np.asarray(result['linesearch_steps']), linewidth = 2)\n",
    "#plt.yscale( 'log')\n",
    "\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.savefig(\"Images/Demo_images/LineSearchAlpha.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For varying epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 0.95\n",
    "rho_inc = 1.5\n",
    "c1 = 0.05\n",
    "c2 = 0.9\n",
    "initial_alpha = 1\n",
    "\n",
    "LineSearchP = []\n",
    "results_LineSearch = []\n",
    "Pmatrix_dist_linVSLineSearchP = []\n",
    "Pmatrix_dist_sinkhornVSLineSearchP = []\n",
    "Pmatrix_dist_GradientAscentVSLineSearchP = []\n",
    "\n",
    "epsilons = [ 0.01,0.05,0.08,0.1 ]\n",
    "for eps in epsilons:\n",
    "\n",
    "    # Line Search\n",
    "    print(\"Line Search....\")    \n",
    "\n",
    "\n",
    "    #Cost matrix\n",
    "    C = distmat(x[1],y[1])\n",
    "\n",
    "\n",
    "    # a and b\n",
    "    a = normalize(np.ones(N[1]))\n",
    "    a = a.reshape(a.shape[0],-1)\n",
    "    b = normalize(np.ones(N[1]))\n",
    "    b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "    #Epsilon \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # epsilon = .05\n",
    "\n",
    "    #Kernel\n",
    "    K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "    f,g = a,b\n",
    "            \n",
    "\n",
    "    print(\"Doing for (\",N[1],N[1],\").\")\n",
    "    print( \" |- Iterating\")\n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.LineSearch(K,a,b,f,g,eps,rho,rho_inc,c1,c2,initial_alpha)\n",
    "    out = Optimizer._update(maxiter=1000)\n",
    "    results_LineSearch.append(out)\n",
    "    end = time.time()\n",
    "    print( \" |- Computing P\")\n",
    "    print( \"\" )\n",
    "    LineSearchP.append(GetP(np.exp(out['potential_f']/eps),K,np.exp(out['potential_g']/eps)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize = (15,6))\n",
    "n=len(results_LineSearch)\n",
    "#plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1 + ||P^T 1 -b||_1$\")\n",
    "for i in range(n):\n",
    "    error_hybrid   = np.asarray(results_LineSearch[i]['error_a']) + np.asarray(results_LineSearch[i]['error_b'])\n",
    "    plt.plot( error_hybrid,label='LineSearch for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Error in log-scale\")\n",
    "plt.legend()\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"Images/Demo_images/Linesearchvaryingepsilon.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Alpha\")\n",
    "\n",
    "for i in range(len(results_LineSearch)):\n",
    "  plt.plot( np.asarray(results_LineSearch[i]['linesearch_steps']),label='LineSearchNewton for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Alpha in log-scale\")\n",
    "plt.legend()\n",
    "# plt.yscale( 'log')\n",
    "plt.savefig(\"Images/Demo_images/AlphaLineSearchNewton.png\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "B4y9X_pPK9kJ"
   },
   "source": [
    "### V. L_BFGS_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4L3OhgpiKm1M",
    "outputId": "3a704484-dea3-4e33-aaf7-a1ab42035db6"
   },
   "outputs": [],
   "source": [
    "BFGSP = []\n",
    "results_BFGS = []\n",
    "\n",
    "times_BFGS = []\n",
    "Pmatrix_dist_linVSBFGSP = []\n",
    "Pmatrix_dist_sinkhornVSBFGSP = []\n",
    "Pmatrix_dist_GradientAscentVSBFGSP = []\n",
    "\n",
    "# BFGS\n",
    "print(\"BFGS....\")\n",
    "\n",
    "for i in range(len(N)):\n",
    "\n",
    "      xi,yi = x[i],y[i]\n",
    "      #Cost matrix\n",
    "      C = distmat(xi,yi)\n",
    "      # a and b\n",
    "      a = normalize(np.ones(N[i]))\n",
    "      a = a.reshape(a.shape[0],-1)\n",
    "      b = normalize(np.ones(N[i]))\n",
    "      b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "      #Epsilon\n",
    "      epsilon = .06\n",
    "\n",
    "      #Kernel\n",
    "      K = np.exp(-C/epsilon)\n",
    "\n",
    "\n",
    "      f,g = a,b\n",
    "\n",
    "\n",
    "      print(\"Doing for \",N[i])\n",
    "      print( \" |- Iterating\")\n",
    "      start = time.time()\n",
    "      Optimizer = computational_OT.L_BFGS_B(K,a,b,f,g,epsilon)\n",
    "      out = Optimizer._update()\n",
    "      results_BFGS.append(out)\n",
    "      end = time.time()\n",
    "      times_BFGS.append(end-start)\n",
    "      print( \" |- Computing P\")\n",
    "      print( \"\" )\n",
    "      BFGSP.append(GetP(np.exp(out['potential_f']/epsilon),K,np.exp(out['potential_g']/epsilon)))\n",
    "\n",
    "     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convergence plot for L-BFGS-B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "j92BoYvVKnHf",
    "outputId": "b777c887-caa5-442c-cad1-1941c9ea78b6"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"$||P1 -a||_1$\")\n",
    "\n",
    "for result in results_BFGS:\n",
    "  plt.plot(np.asarray(result['error_a']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.subplot(2,1,2)\n",
    "\n",
    "plt.title(\"$||P^T 1 -b||_1$\")\n",
    "for result in results_BFGS:\n",
    "  plt.plot(np.asarray(result['error_b']), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.savefig(\"Images/Demo_images/LBFGSconvergence.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Error plots can increase! The error is not the objective function!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "zo2Jvy07KnYg",
    "outputId": "cdda91b4-8ce7-4f99-b56b-03470f11b35f"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.subplot(2,1,1),\n",
    "plt.title(\"Objective Function\")\n",
    "\n",
    "\n",
    "for result in results_BFGS:\n",
    "  plt.plot(np.asarray(result['objectives']), linewidth = 2)\n",
    "#plt.yscale( 'log')\n",
    "plt.legend([str(i) for i in N],loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For varying epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BFGSP = []\n",
    "results_BFGS = []\n",
    "\n",
    "Pmatrix_dist_linVSBFGSP = []\n",
    "Pmatrix_dist_sinkhornVSBFGSP = []\n",
    "Pmatrix_dist_GradientAscentVSBFGSP = []\n",
    "epsilons = [ 0.01,0.02,0.05,0.1,0.15,0.2,0.25,0.3,0.35,0.4,0.45,0.5 ]\n",
    "\n",
    "# BFGS\n",
    "print(\"BFGS....\")\n",
    "N = (400,400)\n",
    "for eps in epsilons:\n",
    "\n",
    "\n",
    "      #Cost matrix\n",
    "      C = distmat(x[1],y[1])\n",
    "      # a and b\n",
    "      a = normalize(np.ones(N[1]))\n",
    "      a = a.reshape(a.shape[0],-1)\n",
    "      b = normalize(np.ones(N[1]))\n",
    "      b = b.reshape(b.shape[0],-1)\n",
    "\n",
    "  \n",
    "\n",
    "      #Kernel\n",
    "      K = np.exp(-C/eps)\n",
    "\n",
    "\n",
    "      f,g = a,b\n",
    "\n",
    "\n",
    "      print(\"Doing for \",(N[1],N[1]))\n",
    "      print(\"\\n Epsilon: \" +str(eps))\n",
    "      \n",
    "      print( \" |- Iterating\")\n",
    "      start = time.time()\n",
    "      Optimizer = computational_OT.L_BFGS_B(K,a,b,f,g,eps)\n",
    "      out = Optimizer._update()\n",
    "      results_BFGS.append(out)\n",
    "      end = time.time()\n",
    "      print( \" |- Computing P\")\n",
    "      print( \"\" )\n",
    "      BFGSP.append(GetP(np.exp(out['potential_f']/epsilon),K,np.exp(out['potential_g']/epsilon)))\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,7))\n",
    "plt.title(\"$$\")\n",
    "plt.title(\"$||P1 -a||_1+||P^T 1 -b||_1$\")\n",
    "\n",
    "for result in results_BFGS:\n",
    "  error=np.asarray(result['error_a'])+np.asarray(result['error_b'])\n",
    "  plt.plot( error,label='LBGFS for $\\epsilon=$'+ str(epsilons[i]), linewidth = 2)\n",
    "plt.yscale( 'log')\n",
    "plt.savefig(\"Images/Demo_images/LBGFSvaryepsilon.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "OptimalTransportSquarevsAnnulus.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
