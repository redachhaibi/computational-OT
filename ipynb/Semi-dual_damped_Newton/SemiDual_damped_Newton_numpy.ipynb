{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook we look into the performance of semi-dual damped Newton in the numpy framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "np.random.seed(1234)\n",
    "plt.rcParams.update( { 'font.size' : 10 } )\n",
    "import computational_OT\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "relative_path_to_new_folder = \"../Images\"\n",
    "os.makedirs( relative_path_to_new_folder, exist_ok = True )\n",
    "if not os.path.isdir( \"../Images/DampedNewton_SemiDual_images_numpy\" ):\n",
    "    os.makedirs( \"../Images/DampedNewton_SemiDual_images_numpy\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\"\"\"To compute distance matrix\"\"\"\n",
    "def distmat( x, y ):\n",
    "    return np.sum( x**2, 0 )[:,None] + np.sum( y**2, 0 )[None,:] - 2 * x.transpose().dot( y )\n",
    "\n",
    "\"\"\"To Normalise a vector\"\"\"\n",
    "normalize = lambda a: a/np.sum( a )\n",
    "\n",
    "\"\"\"To Compute P\"\"\"\n",
    "def GetP( u, K, v ):\n",
    "    return u[:,None] * K * v[None,:]\n",
    "\n",
    "def plotp( x, col, plt, scale = 200, edgecolors = \"k\" ):\n",
    "  return plt.scatter( x[0,:], x[1,:], s = scale, edgecolors = edgecolors, c = col, cmap = 'plasma', linewidths = 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def generate_data( N ):\n",
    "    \"\"\"\n",
    "     N is a list of the size of the data on x and y\n",
    "    \"\"\"\n",
    "    x = np.random.rand( 2, N[0] ) - 0.5\n",
    "    theta = 2 * np.pi * np.random.rand( 1, N[1] )\n",
    "    r = 0.8 + 0.2 * np.random.rand( 1, N[1] )\n",
    "    y = np.vstack( ( r * np.cos( theta ), r * np.sin( theta ) ) )\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "N = [ 500,  600 ]\n",
    "x, y = generate_data( N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy regularized dual-formulation\n",
    "The dual formulation of the entropy regularized OT is given by:\n",
    "$$\n",
    "OT_{\\varepsilon}(\\alpha,\\beta) = \\max_{f\\in \\mathbb{R}^{n}, g\\in\\mathbb{R}^{m}} \\langle f, \\alpha \\rangle + \\langle g, \\beta \\rangle - \\varepsilon\\left(\\langle\\alpha \\otimes \\beta, e^{\\frac{f}{\\varepsilon}}\\odot K \\odot e^{\\frac{g}{\\varepsilon}}  \\rangle-1\\right)\\ ,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\alpha \\in \\mathcal{M}_{1}(\\mathcal{X}),\\ \\beta \\in \\mathcal{M}_{1}(\\mathcal{Y}),\\ \\varepsilon>0,\\ f\\in\\mathbb{R}^{n},\\ g\\in \\mathbb{R}^{m}\\ .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The dual formulation of OT is given by:\n",
    "Using the Shrodinger-bridge equations between the potentials, that is, $g_{j} = -\\varepsilon\\log\\left(\\sum_{i}\\exp\\left(\\frac{f_{i}-C_{ij}}{\\varepsilon}\\right)\\alpha_{i}\\right)\\ , \\ \\forall j = 1,\\dots,m$, we obtain the semi-dual formulation of the objective function, that is,\n",
    "$$\n",
    "Q_{\\varepsilon}^{semi}(f) = \\langle f, \\alpha \\rangle + \\langle g(f,C,\\varepsilon), \\beta \\rangle\\ , \n",
    "$$\n",
    "where\n",
    "$g(f,C,\\varepsilon)_{j} = -\\varepsilon\\log\\left(\\sum_{i}\\exp\\left(\\frac{f_{i}-C_{ij}}{\\varepsilon}\\right)\\alpha_{i}\\right)$.\n",
    "\n",
    "In this setup, the gradients and the Hessian is as follows:\n",
    "$$\n",
    "\\nabla_{f}Q_{\\varepsilon}^{semi}(f)_{i} = \\frac{1}{\\varepsilon}\\alpha_{i}\\left(1-\\sum_{s=1}^{n}\\frac{e^{\\frac{f_{i}-C_{ij}}{\\varepsilon}}\\beta_{s}}{\\left(\\sum_{t=1}^{n}\\alpha_{t}e^{\\frac{f_{t}-C_{ts}}{\\varepsilon}}\\right)}\\right)\\ ,\\ \\forall i = 1,\\dots,n \n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\nabla^{2}_{f}Q_{\\varepsilon}^{semi}(f)_{ii} = \\frac{-1}{\\varepsilon}\\sum_{s=1}^{m}\\left(\\alpha_{i}\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\left(1 - \\alpha_{i}\\left(\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\right)\\beta_{s}\\ ,\\ \\forall i =1,\\dots,n,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\nabla^{2}_{f}Q_{\\varepsilon}^{semi}(f)_{ij} = \\frac{1}{\\varepsilon}\\sum_{s=1}^{m}\\alpha_{i}\\alpha_{j}\\left(\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\left(\\exp\\left(\\frac{f_{j}+g(f,C,\\varepsilon)_{s}-C_{js}}{\\varepsilon}\\right)\\right)\\beta_{s}\\ ,\\ \\forall i \\neq j = 1,\\dots,n\\ .\n",
    "$$\n",
    "Now we plug-in these gradients and Hessian in damped Newton algorithm as we did before.\n",
    "\n",
    "Here we also use the exp-log stabilization to stabilize $g$, the gradients as well as the Hessian as below\n",
    "$$\n",
    "f^{C}_{j} \\leftarrow \\min_{i}(C_{ij}-f_{i})\\ ,  \\ \\forall j = 1,\\dots,m,\\ \\text{the C-transform of f} \\\\\n",
    "g_{j} = -\\varepsilon\\log\\left(\\sum_{i}\\exp\\left(\\frac{f_{i}-C_{ij}+f^{C}_{j}}{\\varepsilon}\\right)\\alpha_{i}\\right)+f^{C}_{j}\\ ,  \\ \\forall j = 1,\\dots,m\\ ,\\\\\n",
    "\\nabla_{f}Q_{\\varepsilon}^{semi}(f)_{i} = \\frac{1}{\\varepsilon}\\alpha_{i}\\left(1-\\sum_{s=1}^{n}\\frac{e^{\\frac{f_{i}-C_{ij}+f^{C}_{j}}{\\varepsilon}}\\beta_{s}}{\\left(\\sum_{t=1}^{n}\\alpha_{t}e^{\\frac{f_{t}-C_{ts}+f^{C}_{j}}{\\varepsilon}}\\right)}\\right)\\ ,\\ \\forall i = 1,\\dots,n\\ , \\\\\n",
    "\\nabla^{2}_{f}Q_{\\varepsilon}^{semi}(f)_{ii} = \\frac{-1}{\\varepsilon}\\sum_{s=1}^{m}\\left(\\alpha_{i}\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\left(1 - \\alpha_{i}\\left(\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\right)\\beta_{s}\\ ,\\ \\forall i =1,\\dots,n\\ , \\\\\n",
    "\\nabla^{2}_{f}Q_{\\varepsilon}^{semi}(f)_{ij} = \\frac{1}{\\varepsilon}\\sum_{s=1}^{m}\\alpha_{i}\\alpha_{j}\\left(\\exp\\left(\\frac{f_{i}+g(f,C,\\varepsilon)_{s}-C_{is}}{\\varepsilon}\\right)\\right)\\left(\\exp\\left(\\frac{f_{j}+g(f,C,\\varepsilon)_{s}-C_{js}}{\\varepsilon}\\right)\\right)\\beta_{s}\\ ,\\ \\forall i \\neq j = 1,\\dots,n\\ .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Semidual damped Newton (Direct inversion / No preconditioning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "withoutprecond_epsilons = [ 1.0, 0.5, 0.05, 0.03, 0.02 ]\n",
    "\n",
    "\n",
    "rho = 0.95\n",
    "c = 0.5\n",
    "Semi_dual_dampedNewtonP = []\n",
    "results_DampedNewtonsemidual = []\n",
    "times_DampedNewtonsemidual = []\n",
    "Hessians_DampedNewtonsemidual= []\n",
    "\n",
    "#Cost matrix\n",
    "C = distmat( x, y )\n",
    "# a and b\n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in withoutprecond_epsilons:\n",
    "    K = np.exp( - C/eps )\n",
    "    # Line Search\n",
    "    print( \" Semi-dual damped Newton for epsilon = \" + str(eps) + \":\" )   \n",
    "    f = a\n",
    "    print( \" Doing for (\",N[0], N[1],\"). \")\n",
    "    print( \" |-  Iterating\" )  \n",
    "    start = time.time()\n",
    "    Optimizer = computational_OT.DampedNewton_SemiDual_np( C, a, b, f, eps, rho, c ) \n",
    "    out = Optimizer._update( maxiter = 50 )\n",
    "    results_DampedNewtonsemidual.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewtonsemidual.append( 1e3 * ( end - start ) )\n",
    "    print( \" |- Computing P \" )\n",
    "    Semi_dual_dampedNewtonP.append( GetP( np.exp( out['potential_f']/eps ), K, np.exp( out['potential_g']/eps ) ) )\n",
    "    print( \" |- Recording (unstabilized) Hessian \\n \" )\n",
    "    mat  = - eps * Optimizer.Hessian\n",
    "    diag = 1/np.sqrt( a )\n",
    "    mat = diag * mat * diag\n",
    "    Hessians_DampedNewtonsemidual.append( mat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 12, 5 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \"$||P1 -a||_1+||P^T 1 -b||_1$\" )\n",
    "for i in range( len( results_DampedNewtonsemidual ) ):\n",
    "  error = np.asarray( results_DampedNewtonsemidual[i]['error'] )\n",
    "  plt.plot( error, label = 'Semi-dual damped Newton for $\\epsilon = $' + str(withoutprecond_epsilons[i]), linewidth = 2 )\n",
    "plt.xlabel( \" Number of iterations \" ) \n",
    "plt.ylabel( \" Error in log-scale \" )\n",
    "plt.legend( loc = \"upper right\" )\n",
    "plt.yscale( 'log' )\n",
    "plt.tight_layout()\n",
    "plt.savefig( \"../Images/DampedNewton_SemiDual_images_numpy/ErrorLinesearchNewton.pdf\", format = 'pdf' )\n",
    "plt.show()\n",
    "print( \" \\n Error plot  s can increase! The error is not the objective function! \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective values plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 12, 5 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \" Objective Function \" )\n",
    "for i in range( len( results_DampedNewtonsemidual ) ):\n",
    "  value = np.asarray( results_DampedNewtonsemidual[i]['objectives'] )\n",
    "  plt.plot( value,label = 'Semi-dual damped Newton for $\\epsilon = $'+ str(withoutprecond_epsilons[i]), linewidth = 2 )\n",
    "\n",
    "plt.xlabel( \" Number of iterations \" )\n",
    "plt.ylabel( \" Objective value \" )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewton_SemiDual_images_numpy/ObjectiveLineSearchNewton.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot displaying the step lengths obtained from the Armijo's conditions at different iterations for different epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 )\n",
    "plt.title( \"Alpha\" )\n",
    "for i in range( len( results_DampedNewtonsemidual ) ):\n",
    "  plt.plot( np.asarray( results_DampedNewtonsemidual[i][\"linesearch_steps\"] ), label = 'Damped Newton for $\\epsilon = $'+ str(withoutprecond_epsilons[i]), linewidth = 2 )\n",
    "plt.xlabel( \"Number of iterations\" )\n",
    "plt.ylabel( \"Alpha in log-scale\" ) \n",
    "plt.legend()\n",
    "plt.savefig( \"../Images/DampedNewton_SemiDual_images_numpy/AlphaLineSearchNewton.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing the spectrum of the eigenvalues of the Hessian at the optimal potentials obtained from the above algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def print_spectral_statistics( mat, stabilize = False ):\n",
    "    if stabilize:\n",
    "        # Stabilizing largest and smallest eigenvalue\n",
    "        min_vector = np.hstack( ( np.ones( N[0] ) ) )\n",
    "        max_vector = np.hstack( ( np.ones(N[0] ) ) )\n",
    "        norm = np.sqrt( N[0] )\n",
    "        min_vector = min_vector/norm\n",
    "        max_vector = max_vector/norm\n",
    "        min_vector = min_vector.reshape( ( min_vector.shape[0], 1 ) )\n",
    "        max_vector = max_vector.reshape( ( max_vector.shape[0], 1 ) )\n",
    "        #\n",
    "        mat = mat + np.dot( min_vector, min_vector.T )\n",
    "        mat = mat - np.dot( max_vector, max_vector.T )\n",
    "    # endif\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort( eig )\n",
    "    eig = eig[ sorting_indices ]\n",
    "    v   = v[ :, sorting_indices ]\n",
    "    \n",
    "    #print( \"Mean eigenvalue: \", np.mean(eig) )\n",
    "    print( \"List of smallest eigenvalues: \", eig[ : 10 ] )\n",
    "    print( \"List of largest  eigenvalues: \", eig[ - 10 : ] )\n",
    "    min_index = np.argmin( eig )\n",
    "    max_index = np.argmax( eig )\n",
    "    min_value = eig[ min_index ]\n",
    "    max_value = eig[ max_index ]\n",
    "    min_vector = v[ :, min_index ]\n",
    "    min_vector = min_vector/min_vector[0]\n",
    "    max_vector = v[ :,max_index ]\n",
    "    max_vector = max_vector/max_vector[0]\n",
    "    condition_number = max_value/min_value\n",
    "    # Test smallest and largest\n",
    "    # print( \"Min eigenvalue vector: \", min_vector)\n",
    "    # print( \"Max eigenvalue vector: \", max_vector)\n",
    "    #\n",
    "    #print( v[:,0]*np.sqrt( self.N1 + self.N2))\n",
    "    #vector = v[:,0]\n",
    "    #test = np.dot( result, vector)\n",
    "    #print( np.linalg.norm(test) )\n",
    "    #print(\"Min absolute eigenvalues: \", min_value)\n",
    "    #print(\"Norm of v-1: \", np.linalg.norm(min_vector-eig_vector))\n",
    "    print( \" Condition number: \", condition_number )\n",
    "    # plt.hist( eig, 50)\n",
    "    # plt.title( \"Histogram of eigenvalues for Hessian\")\n",
    "    # plt.xlabel( \"Eigenvalues\")\n",
    "    # plt.yscale( \"log\" )\n",
    "    # plt.show()\n",
    "    return eig, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "eigs = []\n",
    "eigvecs = []\n",
    "for i in range( len( withoutprecond_epsilons ) ):\n",
    "    eps = withoutprecond_epsilons[i]\n",
    "    print( \" Spectral statistics of Hessian for epsilon = \" + str(eps) )\n",
    "    Hessian = Hessians_DampedNewtonsemidual[i]\n",
    "    ev = print_spectral_statistics( Hessian, stabilize = False )\n",
    "    eigs.append( ev[0] )\n",
    "    eigvecs.append( ev[1] )\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots( figsize = ( 5, 9 ), nrows = len(withoutprecond_epsilons), ncols = 1, sharey = True )\n",
    "plt.title( \" Histogram of eigenvalues. \" )\n",
    "for i in range( len( withoutprecond_epsilons ) ):\n",
    "    ax[i].hist( eigs[i], 50 )\n",
    "    ax[i].set_title( \" $\\epsilon$: \" + str(withoutprecond_epsilons[i]) )\n",
    "    ax[i].set_xlabel( \" Eigenvalues \" )\n",
    "    ax[i].set_yscale( \"log\" )\n",
    "    ax[i].set_xlim( 0, 2 )\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0 ) \n",
    "plt.tight_layout()\n",
    "plt.savefig( \"../Images/DampedNewton_SemiDual_images_numpy/eigenhistunstabilized.pdf\", format = 'pdf' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Semidual damped Newton with preconditioning\n",
    "Here we proceed similar to semi-dual damped Newton but with preconditioning. We consider $t$ eigenvalues of the Hessian and form the following preconditioning matrix:\n",
    "$$\n",
    "P = \\left(I_{n+m}-\\sum_{i-1}^{t}\\left(1 - \\frac{1}{\\sqrt{\\lambda_{i}}}\\right)y_{i}y_{i}^{T}\\right)\\ .\n",
    "$$\n",
    "Now, at the $k^{th}$ iteration we solve the following equation:\n",
    "$$\n",
    "(P\\nabla^{2}Q_{\\varepsilon}(f,g)P)(Pp_{k})=P\\nabla Q_{\\varepsilon}(f,g)\\ ,\n",
    "$$\n",
    "using iterative inversion methods such as \"Conjugate gradient\" and \"GMRES\" to get the update direction $p_{k}$, following which we use the Armijo condition to obtain the step size $\\alpha_{k}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preconditioning eigenvectors \n",
    "The Hessian of damped Newton in the semi-dual formulation are in the interval  [0,1]. The following function collects the eigenvectors corresponding to the eigenvalues that are less than 0 and greater than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_preconditioners( num_eigs, modified_Hessian, ansatz = True ):\n",
    "    # Diagonalize\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh( modified_Hessian )\n",
    "    sorting_indices = np.argsort( eigenvalues )\n",
    "    eigenvalues  = eigenvalues[ sorting_indices ]\n",
    "    eigenvectors = eigenvectors[ : , sorting_indices ]\n",
    "    # Form null vector\n",
    "    if not ansatz:\n",
    "        null_vector = eigenvectors[:, 0]\n",
    "    else:\n",
    "        null_vector = np.ones( N[0] ) \n",
    "        norm = np.sqrt( N[0] )\n",
    "        null_vector = null_vector/norm\n",
    "    # Form other vectors\n",
    "    indices1 = []\n",
    "    for i in range( num_eigs ):\n",
    "        indices1.append( i + 1 )\n",
    "    \n",
    "    # For eigenvectors corresponding to eigenvalues greater than 1\n",
    "    indices2 =  np.where( eigenvalues > 1  )[0].tolist()\n",
    "    indices = indices1 + indices2[ - num_eigs: ]\n",
    "    precond_vectors = eigenvectors[ :, indices ]\n",
    "    \n",
    "    precond_vectors = []\n",
    "    for index in indices:\n",
    "        precond_vectors.append( eigenvectors[ :, index ] )\n",
    "    #\n",
    "    return null_vector, precond_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = 30\n",
    "null_vector, precond_vectors = build_preconditioners( num_eigs,  Hessians_DampedNewtonsemidual[-1], ansatz = False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "withprecond_epsilons = [ 1.0, 0.5, 0.05, 0.03, 0.02, 0.01 ]\n",
    "rho = 0.95\n",
    "c = 0.5\n",
    "reset_starting_point = True  \n",
    "final_modified_Hessians = []\n",
    "Semi_dual_dampedNewtonP = []\n",
    "results_DampedNewton_with_preconditioner_SemiDual = []\n",
    "times_DampedNewton_with_preconditioner_SemiDual = []\n",
    "f = None\n",
    "# Cost matrix\n",
    "C = distmat( x, y )\n",
    "# a and b   \n",
    "a = normalize( np.ones( N[0] ) )\n",
    "b = normalize( np.ones( N[1] ) )\n",
    "for eps in withprecond_epsilons :\n",
    "    # Line Search\n",
    "    print( \" Semi-dual damped Newton for epsilon = \"+str(eps)+\":\" )    \n",
    "    if f is None:\n",
    "        f = a * 0\n",
    "    print( \" Doing for (\",N[0], N[1],\"). \" )\n",
    "    print( \" |- Iterating\" )  \n",
    "\n",
    "    start = time.time() \n",
    "    Optimizer = computational_OT.DampedNewton_with_precodonditioner_SemiDual_np( C, a, b, f, eps, rho, c, null_vector, precond_vectors[:] )\n",
    "    out = Optimizer._update( maxiter = 50, iterative_inversion = 100, version = None, debug = False, optType = 'cg' )\n",
    "    results_DampedNewton_with_preconditioner_SemiDual.append( out )\n",
    "    end = time.time()\n",
    "    times_DampedNewton_with_preconditioner_SemiDual.append( 1e3 * ( end - start ) )\n",
    "    print( \" |- Computing P\" )\n",
    "    if not reset_starting_point:\n",
    "        f = Optimizer.x[:a.shape[0]]\n",
    "        g = Optimizer.x[a.shape[0]:]\n",
    "    Semi_dual_dampedNewtonP.append( GetP( np.exp( out['potential_f']/eps ), np.exp( -C/eps ), np.exp( out['potential_g']/eps ) ) )\n",
    "    final_modified_Hessians.append( Optimizer.modified_Hessian )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update( { 'font.size' : 10 } )\n",
    "plt.figure( figsize = ( 20, 7 ) )   \n",
    "plt.title( \"$$\" ) \n",
    "plt.title( \" $||P1 -a||_1+||P^T1 -b||_1$ \" ) \n",
    "for i in range( len( results_DampedNewton_with_preconditioner_SemiDual ) ): \n",
    "  error = np.asarray( results_DampedNewton_with_preconditioner_SemiDual[i]['error'] ) \n",
    "  plt.plot( error, label = 'Semi-dual damped Newton for $\\epsilon = $'+ str(withprecond_epsilons[i]), linewidth = 2 ) \n",
    "plt.xlabel( \" Number of iterations \" )  \n",
    "plt.ylabel( \" Error in log-scale \" )  \n",
    "plt.legend() \n",
    "plt.yscale( 'log' ) \n",
    "plt.savefig( \"../Images/DampedNewton_SemiDual_images_numpy/ErrorDampedNewtonwithPrec+ond_final_cg.png\" ) \n",
    "plt.show() \n",
    "print( \"\\n Error plots can increase! The error is not the objective function!\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objective function plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure( figsize = ( 12, 5 ) )\n",
    "plt.title( \"$$\" )\n",
    "plt.title( \" Objective Function \" )\n",
    "for i in range( len(results_DampedNewton_with_preconditioner_SemiDual) ):\n",
    "  value = np.asarray( results_DampedNewton_with_preconditioner_SemiDual[i]['objectives'] )\n",
    "  plt.plot( value, label = 'Damped Newton for $\\epsilon = $' + str(withprecond_epsilons[i]), linewidth = 2 )\n",
    "plt.xlabel( \" Number of iterations \" )\n",
    "plt.ylabel( \" Objective value \" )\n",
    "plt.yscale( 'log' )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot displaying the step lengths obtained from the Armijo's conditions at different iterations for different epsilons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure( figsize = ( 20, 7 ) )\n",
    "plt.subplot( 2, 1, 1 )\n",
    "plt.title( \" Alpha \" )\n",
    "for i in range( len( results_DampedNewton_with_preconditioner_SemiDual ) ):\n",
    "  plt.plot( np.asarray( results_DampedNewton_with_preconditioner_SemiDual[i][\"linesearch_steps\"] ), label = 'Damped Newton for $\\epsilon = $'+ str(withprecond_epsilons[i]), linewidth = 2 )\n",
    "plt.xlabel( \"Number of iteration  s\" )\n",
    "plt.ylabel( \"Alpha in log-scale\" )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of the time stamps recorded at different blocks of the iterative inversion method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "        \"Preconditioning 1: Form E data\",\n",
    "        \"Preconditioning 2: Form P data\",\n",
    "        \"Form preconditioning functions\",\n",
    "        \"Invert the linear system for p_k\",\n",
    "        \"Unwinding\",\n",
    "        \"Complete code block\"\n",
    "        ]\n",
    "\n",
    "plt.figure( figsize = ( 20, 10 ) )  \n",
    "for j in range( len(results_DampedNewton_with_preconditioner_SemiDual[0]['timings'][0]) ):\n",
    "  values = []\n",
    "  for i in range( len(results_DampedNewton_with_preconditioner_SemiDual) ):\n",
    "    mean = 0\n",
    "    for k in range( len(results_DampedNewton_with_preconditioner_SemiDual[i]['timings']) ):\n",
    "      mean += results_DampedNewton_with_preconditioner_SemiDual[i]['timings'][k][j]\n",
    "    mean = mean/len( results_DampedNewton_with_preconditioner_SemiDual[i]['timings'] ) \n",
    "    values.append( mean )\n",
    "  if len(withprecond_epsilons) == len(values):\n",
    "    plt.plot( withprecond_epsilons, np.asarray(values), label = text[j], linewidth = 2 )\n",
    "    plt.legend( loc = 'upper left' )\n",
    "plt.xlabel( \"$\\epsilon$\" )\n",
    "plt.ylabel( \"Time in ms\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking into the preconditioning\n",
    "Here we perform the preconditioning of the Hessians for different number of preconditioning vectors and plot the hitograms of the eigenvalues of the preconditoned Hessian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eigs = [ 0, 30, 50, 100, 400, 499 ]\n",
    "preconditioned_Hessians = {}\n",
    "for numeigs  in  range(len(num_eigs)):\n",
    "    preconditioned_Hessians[ num_eigs[ numeigs ] ] = []\n",
    "    for i in  range(len(withoutprecond_epsilons)):\n",
    "        diag   = 1/np.sqrt(np.diag( Hessians_DampedNewtonsemidual[i] ).flatten())\n",
    "        result = diag[:,None] * Hessians_DampedNewtonsemidual[i] * diag[None,:]\n",
    "        if num_eigs[numeigs] != 0:\n",
    "            null_vector, precond_vectors = build_preconditioners( num_eigs[ numeigs ],  Hessians_DampedNewtonsemidual[i], ansatz = False )\n",
    "            # vector = null_vector\n",
    "            # vector = vector/diag\n",
    "            # vector = vector/np.linalg.norm( vector )\n",
    "            # vector = vector.reshape( ( len( vector ), 1) )\n",
    "            # result = result + np.dot( vector, vector.T )\n",
    "            y_ = np.array( precond_vectors ).T # Matrix of size n by k\n",
    "            # Compute eigenvalues\n",
    "            Ay = np.dot( result, y_ )\n",
    "            eigenvalues = np.sum( y_ * Ay, axis = 0 )\n",
    "            # Compute P_matrix = id + y*diag(values)*y.T\n",
    "            values = ( 1/np.sqrt(eigenvalues) - 1 )    # Vector of size k\n",
    "            z = y_ * values[None,:]\n",
    "            B = np.dot( Ay, z.T )\n",
    "            C_ = z @ np.dot( y_.T, Ay ) @ z.T\n",
    "            result = result + B + B.T + C_\n",
    "        preconditioned_Hessians[ num_eigs[ numeigs ] ].append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spectral_decomposition( mat ):\n",
    "    eig, v = np.linalg.eigh( mat )\n",
    "    sorting_indices = np.argsort( eig )\n",
    "    eig = eig[ sorting_indices ]\n",
    "    v   = v[ : , sorting_indices ]\n",
    "    print( \"List of smallest eigenvalues: \", eig[ : 10 ] )\n",
    "    print( \"List of largest  eigenvalues: \", eig[ - 10 : ] )\n",
    "    return eig, v\n",
    "\n",
    "\n",
    "eigs = {}\n",
    "for numeigs in  range(len(num_eigs)):\n",
    "    eigs[ num_eigs[ numeigs ] ] = []\n",
    "    print(\" For number of preconditioning eigenvectors = \", num_eigs[ numeigs ])\n",
    "    for i in range(len(withoutprecond_epsilons)):\n",
    "        eps = withoutprecond_epsilons[i]\n",
    "        print( \"Spectral statistics of Hessian for epsilon = \"+str(eps) )\n",
    "        ev = spectral_decomposition( preconditioned_Hessians[ num_eigs[ numeigs ] ][i])\n",
    "        eigs[ num_eigs[ numeigs ] ].append( ev[0] )\n",
    "        print(\"\")\n",
    "    print(\"------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot displays different size of preconditioning on the Hessian obtained from the semi-dual damped Newton without preconditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update( { 'font.size' : 90 } )\n",
    "fig, ax = plt.subplots( figsize = ( 120, 130 ), nrows = len(num_eigs), ncols = len(withoutprecond_epsilons), sharey = True, sharex = False )\n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.3 )\n",
    "p = np.log10( 0.5 )   \n",
    "for numeigs in range(len(num_eigs)):\n",
    "    for i in range(len(withoutprecond_epsilons)):\n",
    "        ax[ numeigs ][i].hist( eigs[ num_eigs[ numeigs ] ][i], 50, rwidth = 0.9 )\n",
    "        ax[ numeigs ][i].set_title( \" k = \"+str(num_eigs[ numeigs ])+\", $\\epsilon$ = \" +str(withoutprecond_epsilons[i])+ \"\" )\n",
    "        ax[ numeigs ][i].set_ylim( ymin = 10 ** p )\n",
    "        ax[ numeigs ][i].set_yscale( \"log\" )    \n",
    "ax[ len(num_eigs) - 1 ][ len(withoutprecond_epsilons) - 1 ].set_xticks([ 0, 1, 2 ])  \n",
    "plt.subplots_adjust( wspace = 0, hspace = 0.4 )\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_computational-OT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
